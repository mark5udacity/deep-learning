{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TensorFlow Neural Network Lab</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/notmnist.png\">\n",
    "In this lab, you'll use all the tools you learned from *Introduction to TensorFlow* to label images of English letters! The data you are using, <a href=\"http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html\">notMNIST</a>, consists of images of a letter from A to J in different fonts.\n",
    "\n",
    "The above images are a few examples of the data you'll be training on. After training the network, you will compare your prediction model against test data. Your goal, by the end of this lab, is to make predictions against that test set with at least an 80% accuracy. Let's jump in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this lab, you first need to import all the necessary modules. Run the code below. If it runs successfully, it will print \"`All modules imported`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notMNIST dataset is too large for many computers to handle.  It contains 500,000 images for just training.  You'll be using a subset of this data, 15,000 images for each label (A-J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading notMNIST_train.zip...\n",
      "Download Finished\n",
      "Downloading notMNIST_test.zip...\n",
      "Download Finished\n",
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/210001 [00:00<?, ?files/s]\u001b[A\n",
      "  0%|          | 168/210001 [00:00<02:05, 1677.25files/s]\u001b[A\n",
      "  0%|          | 391/210001 [00:00<01:55, 1809.88files/s]\u001b[A\n",
      "  0%|          | 658/210001 [00:00<01:44, 2002.52files/s]\u001b[A\n",
      "  0%|          | 894/210001 [00:00<01:39, 2097.15files/s]\u001b[A\n",
      "  1%|          | 1114/210001 [00:00<01:38, 2126.36files/s]\u001b[A\n",
      "  1%|          | 1304/210001 [00:00<01:41, 2051.04files/s]\u001b[A\n",
      "  1%|          | 1494/210001 [00:00<02:12, 1569.49files/s]\u001b[A\n",
      "  1%|          | 1660/210001 [00:00<02:12, 1577.15files/s]\u001b[A\n",
      "  1%|          | 1823/210001 [00:01<02:19, 1494.51files/s]\u001b[A\n",
      "  1%|          | 2068/210001 [00:01<02:02, 1691.37files/s]\u001b[A\n",
      "  1%|          | 2287/210001 [00:01<01:54, 1814.44files/s]\u001b[A\n",
      "  1%|          | 2479/210001 [00:01<01:52, 1840.89files/s]\u001b[A\n",
      "  1%|▏         | 2714/210001 [00:01<01:45, 1967.09files/s]\u001b[A\n",
      "  1%|▏         | 2987/210001 [00:01<01:36, 2146.17files/s]\u001b[A\n",
      "  2%|▏         | 3212/210001 [00:01<01:39, 2086.01files/s]\u001b[A\n",
      "  2%|▏         | 3429/210001 [00:01<01:42, 2015.32files/s]\u001b[A\n",
      "  2%|▏         | 3643/210001 [00:01<01:40, 2049.36files/s]\u001b[A\n",
      "  2%|▏         | 3877/210001 [00:01<01:36, 2127.53files/s]\u001b[A\n",
      "  2%|▏         | 4094/210001 [00:02<01:41, 2025.55files/s]\u001b[A\n",
      "  2%|▏         | 4301/210001 [00:02<01:43, 1992.91files/s]\u001b[A\n",
      "  2%|▏         | 4503/210001 [00:02<01:45, 1943.40files/s]\u001b[A\n",
      "  2%|▏         | 4735/210001 [00:02<01:40, 2042.57files/s]\u001b[A\n",
      "  2%|▏         | 4945/210001 [00:02<01:39, 2056.88files/s]\u001b[A\n",
      "  2%|▏         | 5153/210001 [00:02<01:43, 1985.10files/s]\u001b[A\n",
      "  3%|▎         | 5354/210001 [00:02<01:45, 1934.12files/s]\u001b[A\n",
      "  3%|▎         | 5550/210001 [00:02<01:46, 1927.68files/s]\u001b[A\n",
      "  3%|▎         | 5744/210001 [00:02<01:46, 1917.58files/s]\u001b[A\n",
      "  3%|▎         | 5997/210001 [00:03<01:38, 2064.65files/s]\u001b[A\n",
      "  3%|▎         | 6227/210001 [00:03<01:35, 2127.90files/s]\u001b[A\n",
      "  3%|▎         | 6458/210001 [00:03<01:33, 2178.58files/s]\u001b[A\n",
      "  3%|▎         | 6679/210001 [00:03<01:34, 2161.48files/s]\u001b[A\n",
      "  3%|▎         | 6934/210001 [00:03<01:29, 2264.54files/s]\u001b[A\n",
      "  3%|▎         | 7163/210001 [00:03<01:31, 2220.36files/s]\u001b[A\n",
      "  4%|▎         | 7411/210001 [00:03<01:28, 2288.75files/s]\u001b[A\n",
      "  4%|▎         | 7664/210001 [00:03<01:25, 2355.45files/s]\u001b[A\n",
      "  4%|▍         | 7902/210001 [00:03<01:39, 2034.09files/s]\u001b[A\n",
      "  4%|▍         | 8115/210001 [00:04<01:50, 1830.42files/s]\u001b[A\n",
      "  4%|▍         | 8309/210001 [00:04<01:54, 1767.43files/s]\u001b[A\n",
      "  4%|▍         | 8505/210001 [00:04<01:50, 1819.77files/s]\u001b[A\n",
      "  4%|▍         | 8693/210001 [00:04<02:19, 1447.72files/s]\u001b[A\n",
      "  4%|▍         | 8885/210001 [00:04<02:08, 1561.18files/s]\u001b[A\n",
      "  4%|▍         | 9055/210001 [00:04<02:16, 1468.77files/s]\u001b[A\n",
      "  4%|▍         | 9235/210001 [00:04<02:09, 1552.33files/s]\u001b[A\n",
      "  4%|▍         | 9400/210001 [00:04<02:11, 1520.74files/s]\u001b[A\n",
      "  5%|▍         | 9602/210001 [00:04<02:02, 1633.99files/s]\u001b[A\n",
      "  5%|▍         | 9820/210001 [00:05<01:53, 1763.89files/s]\u001b[A\n",
      "  5%|▍         | 10034/210001 [00:05<01:47, 1858.54files/s]\u001b[A\n",
      "  5%|▍         | 10227/210001 [00:05<01:53, 1766.96files/s]\u001b[A\n",
      "  5%|▍         | 10450/210001 [00:05<01:45, 1884.08files/s]\u001b[A\n",
      "  5%|▌         | 10645/210001 [00:05<02:06, 1577.42files/s]\u001b[A\n",
      "  5%|▌         | 10816/210001 [00:05<02:04, 1601.64files/s]\u001b[A\n",
      "  5%|▌         | 10986/210001 [00:05<02:06, 1578.70files/s]\u001b[A\n",
      "  5%|▌         | 11151/210001 [00:05<02:05, 1580.62files/s]\u001b[A\n",
      "  5%|▌         | 11334/210001 [00:05<02:00, 1642.34files/s]\u001b[A\n",
      "  5%|▌         | 11515/210001 [00:06<01:57, 1684.60files/s]\u001b[A\n",
      "  6%|▌         | 11687/210001 [00:06<02:16, 1454.33files/s]\u001b[A\n",
      "  6%|▌         | 11875/210001 [00:06<02:07, 1558.95files/s]\u001b[A\n",
      "  6%|▌         | 12039/210001 [00:06<02:15, 1464.03files/s]\u001b[A\n",
      "  6%|▌         | 12192/210001 [00:06<02:16, 1444.26files/s]\u001b[A\n",
      "  6%|▌         | 12359/210001 [00:06<02:11, 1504.92files/s]\u001b[A\n",
      "  6%|▌         | 12514/210001 [00:06<02:17, 1438.17files/s]\u001b[A\n",
      "  6%|▌         | 12662/210001 [00:06<02:28, 1325.31files/s]\u001b[A\n",
      "  6%|▌         | 12799/210001 [00:07<02:30, 1311.98files/s]\u001b[A\n",
      "  6%|▌         | 12977/210001 [00:07<02:18, 1423.44files/s]\u001b[A\n",
      "  6%|▋         | 13186/210001 [00:07<02:05, 1573.22files/s]\u001b[A\n",
      "  6%|▋         | 13383/210001 [00:07<01:57, 1669.53files/s]\u001b[A\n",
      "  6%|▋         | 13558/210001 [00:07<02:07, 1538.52files/s]\u001b[A\n",
      "  7%|▋         | 13720/210001 [00:07<02:06, 1546.20files/s]\u001b[A\n",
      "  7%|▋         | 13881/210001 [00:07<02:08, 1520.87files/s]\u001b[A\n",
      "  7%|▋         | 14037/210001 [00:07<02:08, 1527.05files/s]\u001b[A\n",
      "  7%|▋         | 14219/210001 [00:07<02:02, 1603.91files/s]\u001b[A\n",
      "  7%|▋         | 14383/210001 [00:08<02:04, 1567.78files/s]\u001b[A\n",
      "  7%|▋         | 14560/210001 [00:08<02:01, 1607.46files/s]\u001b[A\n",
      "  7%|▋         | 14738/210001 [00:08<02:00, 1619.87files/s]\u001b[A\n",
      "  7%|▋         | 14939/210001 [00:08<01:54, 1698.24files/s]\u001b[A\n",
      "  7%|▋         | 15143/210001 [00:08<01:49, 1786.23files/s]\u001b[A\n",
      "  7%|▋         | 15325/210001 [00:08<01:50, 1768.52files/s]\u001b[A\n",
      "  7%|▋         | 15523/210001 [00:08<01:46, 1824.09files/s]\u001b[A\n",
      "  7%|▋         | 15708/210001 [00:08<01:51, 1743.49files/s]\u001b[A\n",
      "  8%|▊         | 15885/210001 [00:08<02:11, 1481.33files/s]\u001b[A\n",
      "  8%|▊         | 16057/210001 [00:09<02:05, 1539.74files/s]\u001b[A\n",
      "  8%|▊         | 16218/210001 [00:09<02:07, 1523.99files/s]\u001b[A\n",
      "  8%|▊         | 16399/210001 [00:09<02:02, 1576.73files/s]\u001b[A\n",
      "  8%|▊         | 16588/210001 [00:09<01:57, 1643.65files/s]\u001b[A\n",
      "  8%|▊         | 16803/210001 [00:09<01:49, 1765.99files/s]\u001b[A\n",
      "  8%|▊         | 16997/210001 [00:09<01:46, 1813.62files/s]\u001b[A\n",
      "  8%|▊         | 17193/210001 [00:09<01:43, 1854.28files/s]\u001b[A\n",
      "  8%|▊         | 17418/210001 [00:09<01:38, 1957.26files/s]\u001b[A\n",
      "  8%|▊         | 17681/210001 [00:09<01:30, 2119.01files/s]\u001b[A\n",
      "  9%|▊         | 17957/210001 [00:09<01:24, 2277.33files/s]\u001b[A\n",
      "  9%|▊         | 18222/210001 [00:10<01:20, 2377.56files/s]\u001b[A\n",
      "  9%|▉         | 18467/210001 [00:10<01:21, 2355.61files/s]\u001b[A\n",
      "  9%|▉         | 18708/210001 [00:10<01:21, 2344.81files/s]\u001b[A\n",
      "  9%|▉         | 18946/210001 [00:10<01:30, 2122.38files/s]\u001b[A\n",
      "  9%|▉         | 19202/210001 [00:10<01:25, 2236.44files/s]\u001b[A\n",
      "  9%|▉         | 19432/210001 [00:10<01:28, 2161.69files/s]\u001b[A\n",
      "  9%|▉         | 19700/210001 [00:10<01:22, 2293.73files/s]\u001b[A\n",
      "  9%|▉         | 19935/210001 [00:10<01:25, 2230.48files/s]\u001b[A\n",
      " 10%|▉         | 20163/210001 [00:10<01:31, 2074.49files/s]\u001b[A\n",
      " 10%|▉         | 20376/210001 [00:11<01:41, 1861.73files/s]\u001b[A\n",
      " 10%|▉         | 20570/210001 [00:11<01:48, 1745.89files/s]\u001b[A\n",
      " 10%|▉         | 20752/210001 [00:11<02:07, 1482.85files/s]\u001b[A\n",
      " 10%|▉         | 20912/210001 [00:11<02:08, 1474.82files/s]\u001b[A\n",
      " 10%|█         | 21069/210001 [00:11<02:05, 1501.42files/s]\u001b[A\n",
      " 10%|█         | 21225/210001 [00:11<02:04, 1515.34files/s]\u001b[A\n",
      " 10%|█         | 21465/210001 [00:11<01:50, 1700.27files/s]\u001b[A\n",
      " 10%|█         | 21833/210001 [00:11<01:32, 2025.00files/s]\u001b[A\n",
      " 11%|█         | 22069/210001 [00:12<01:36, 1952.57files/s]\u001b[A\n",
      " 11%|█         | 22289/210001 [00:12<01:38, 1914.38files/s]\u001b[A\n",
      " 11%|█         | 22609/210001 [00:12<01:26, 2176.33files/s]\u001b[A\n",
      " 11%|█         | 22898/210001 [00:12<01:19, 2348.72files/s]\u001b[A\n",
      " 11%|█         | 23164/210001 [00:12<01:16, 2429.27files/s]\u001b[A\n",
      " 11%|█         | 23441/210001 [00:12<01:14, 2520.59files/s]\u001b[A\n",
      " 11%|█▏        | 23761/210001 [00:12<01:09, 2687.02files/s]\u001b[A\n",
      " 11%|█▏        | 24041/210001 [00:12<01:13, 2532.95files/s]\u001b[A\n",
      " 12%|█▏        | 24304/210001 [00:12<01:16, 2420.47files/s]\u001b[A\n",
      " 12%|█▏        | 24554/210001 [00:12<01:18, 2367.14files/s]\u001b[A\n",
      " 12%|█▏        | 24808/210001 [00:13<01:16, 2413.15files/s]\u001b[A\n",
      " 12%|█▏        | 25054/210001 [00:13<01:20, 2290.88files/s]\u001b[A\n",
      " 12%|█▏        | 25342/210001 [00:13<01:15, 2439.71files/s]\u001b[A\n",
      " 12%|█▏        | 25592/210001 [00:13<01:19, 2309.66files/s]\u001b[A\n",
      " 12%|█▏        | 25829/210001 [00:13<01:22, 2240.72files/s]\u001b[A\n",
      " 12%|█▏        | 26058/210001 [00:13<01:21, 2245.90files/s]\u001b[A\n",
      " 13%|█▎        | 26325/210001 [00:13<01:17, 2357.22files/s]\u001b[A\n",
      " 13%|█▎        | 26658/210001 [00:13<01:10, 2583.16files/s]\u001b[A\n",
      " 13%|█▎        | 26997/210001 [00:13<01:05, 2780.57files/s]\u001b[A\n",
      " 13%|█▎        | 27309/210001 [00:14<01:03, 2873.95files/s]\u001b[A\n",
      " 13%|█▎        | 27605/210001 [00:14<01:12, 2505.54files/s]\u001b[A\n",
      " 13%|█▎        | 27870/210001 [00:14<01:20, 2272.43files/s]\u001b[A\n",
      " 13%|█▎        | 28112/210001 [00:14<01:26, 2099.80files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 28335/210001 [00:14<01:31, 1995.77files/s]\u001b[A\n",
      " 14%|█▎        | 28546/210001 [00:14<01:29, 2026.77files/s]\u001b[A\n",
      " 14%|█▎        | 28771/210001 [00:14<01:27, 2077.47files/s]\u001b[A\n",
      " 14%|█▍        | 29072/210001 [00:14<01:19, 2289.67files/s]\u001b[A\n",
      " 14%|█▍        | 29397/210001 [00:15<01:11, 2510.00files/s]\u001b[A\n",
      " 14%|█▍        | 29750/210001 [00:15<01:05, 2747.72files/s]\u001b[A\n",
      " 14%|█▍        | 30071/210001 [00:15<01:02, 2871.34files/s]\u001b[A\n",
      " 14%|█▍        | 30431/210001 [00:15<00:58, 3055.83files/s]\u001b[A\n",
      " 15%|█▍        | 30772/210001 [00:15<00:56, 3153.63files/s]\u001b[A\n",
      " 15%|█▍        | 31097/210001 [00:15<00:56, 3162.45files/s]\u001b[A\n",
      " 15%|█▍        | 31420/210001 [00:15<01:01, 2908.47files/s]\u001b[A\n",
      " 15%|█▌        | 31774/210001 [00:15<00:58, 3071.84files/s]\u001b[A\n",
      " 15%|█▌        | 32157/210001 [00:15<00:54, 3264.04files/s]\u001b[A\n",
      " 15%|█▌        | 32518/210001 [00:15<00:52, 3359.11files/s]\u001b[A\n",
      " 16%|█▌        | 32865/210001 [00:16<00:52, 3389.86files/s]\u001b[A\n",
      " 16%|█▌        | 33232/210001 [00:16<00:50, 3467.75files/s]\u001b[A\n",
      " 16%|█▌        | 33595/210001 [00:16<00:50, 3513.05files/s]\u001b[A\n",
      " 16%|█▌        | 33952/210001 [00:16<00:49, 3529.65files/s]\u001b[A\n",
      " 16%|█▋        | 34308/210001 [00:16<00:49, 3529.35files/s]\u001b[A\n",
      " 17%|█▋        | 34663/210001 [00:16<00:50, 3483.60files/s]\u001b[A\n",
      " 17%|█▋        | 35013/210001 [00:16<00:50, 3437.26files/s]\u001b[A\n",
      " 17%|█▋        | 35379/210001 [00:16<00:49, 3498.91files/s]\u001b[A\n",
      " 17%|█▋        | 35736/210001 [00:16<00:49, 3518.44files/s]\u001b[A\n",
      " 17%|█▋        | 36089/210001 [00:16<00:49, 3513.98files/s]\u001b[A\n",
      " 17%|█▋        | 36457/210001 [00:17<00:48, 3561.26files/s]\u001b[A\n",
      " 18%|█▊        | 36814/210001 [00:17<00:48, 3543.34files/s]\u001b[A\n",
      " 18%|█▊        | 37173/210001 [00:17<00:48, 3555.93files/s]\u001b[A\n",
      " 18%|█▊        | 37529/210001 [00:17<00:49, 3476.77files/s]\u001b[A\n",
      " 18%|█▊        | 37878/210001 [00:17<00:49, 3471.88files/s]\u001b[A\n",
      " 18%|█▊        | 38226/210001 [00:17<00:49, 3468.12files/s]\u001b[A\n",
      " 18%|█▊        | 38577/210001 [00:17<00:49, 3479.69files/s]\u001b[A\n",
      " 19%|█▊        | 38929/210001 [00:17<00:49, 3489.67files/s]\u001b[A\n",
      " 19%|█▊        | 39279/210001 [00:17<00:49, 3482.53files/s]\u001b[A\n",
      " 19%|█▉        | 39642/210001 [00:17<00:48, 3524.09files/s]\u001b[A\n",
      " 19%|█▉        | 39995/210001 [00:18<00:48, 3502.34files/s]\u001b[A\n",
      " 19%|█▉        | 40362/210001 [00:18<00:47, 3550.46files/s]\u001b[A\n",
      " 19%|█▉        | 40722/210001 [00:18<00:47, 3563.80files/s]\u001b[A\n",
      " 20%|█▉        | 41079/210001 [00:18<00:48, 3517.97files/s]\u001b[A\n",
      " 20%|█▉        | 41432/210001 [00:18<00:48, 3509.93files/s]\u001b[A\n",
      " 20%|█▉        | 41792/210001 [00:18<00:47, 3535.61files/s]\u001b[A\n",
      " 20%|██        | 42164/210001 [00:18<00:46, 3587.36files/s]\u001b[A\n",
      " 20%|██        | 42524/210001 [00:18<00:46, 3569.99files/s]\u001b[A\n",
      " 20%|██        | 42882/210001 [00:18<00:46, 3562.28files/s]\u001b[A\n",
      " 21%|██        | 43239/210001 [00:18<00:47, 3501.30files/s]\u001b[A\n",
      " 21%|██        | 43614/210001 [00:19<00:46, 3570.75files/s]\u001b[A\n",
      " 21%|██        | 43984/210001 [00:19<00:46, 3606.55files/s]\u001b[A\n",
      " 21%|██        | 44346/210001 [00:19<00:46, 3565.34files/s]\u001b[A\n",
      " 21%|██▏       | 44703/210001 [00:19<00:48, 3430.39files/s]\u001b[A\n",
      " 21%|██▏       | 45074/210001 [00:19<00:46, 3509.38files/s]\u001b[A\n",
      " 22%|██▏       | 45440/210001 [00:19<00:46, 3551.63files/s]\u001b[A\n",
      " 22%|██▏       | 45808/210001 [00:19<00:45, 3587.71files/s]\u001b[A\n",
      " 22%|██▏       | 46168/210001 [00:19<00:45, 3584.56files/s]\u001b[A\n",
      " 22%|██▏       | 46557/210001 [00:19<00:44, 3670.20files/s]\u001b[A\n",
      " 22%|██▏       | 46937/210001 [00:20<00:43, 3706.22files/s]\u001b[A\n",
      " 23%|██▎       | 47311/210001 [00:20<00:43, 3713.77files/s]\u001b[A\n",
      " 23%|██▎       | 47683/210001 [00:20<00:43, 3697.17files/s]\u001b[A\n",
      " 23%|██▎       | 48061/210001 [00:20<00:43, 3720.60files/s]\u001b[A\n",
      " 23%|██▎       | 48434/210001 [00:20<00:43, 3682.55files/s]\u001b[A\n",
      " 23%|██▎       | 48818/210001 [00:20<00:43, 3728.20files/s]\u001b[A\n",
      " 23%|██▎       | 49195/210001 [00:20<00:43, 3737.95files/s]\u001b[A\n",
      " 24%|██▎       | 49570/210001 [00:20<00:43, 3726.73files/s]\u001b[A\n",
      " 24%|██▍       | 49943/210001 [00:20<00:43, 3717.65files/s]\u001b[A\n",
      " 24%|██▍       | 50315/210001 [00:20<00:43, 3710.33files/s]\u001b[A\n",
      " 24%|██▍       | 50695/210001 [00:21<00:42, 3735.99files/s]\u001b[A\n",
      " 24%|██▍       | 51072/210001 [00:21<00:42, 3743.81files/s]\u001b[A\n",
      " 24%|██▍       | 51447/210001 [00:21<00:43, 3671.70files/s]\u001b[A\n",
      " 25%|██▍       | 51826/210001 [00:21<00:42, 3701.65files/s]\u001b[A\n",
      " 25%|██▍       | 52197/210001 [00:21<00:42, 3704.04files/s]\u001b[A\n",
      " 25%|██▌       | 52577/210001 [00:21<00:42, 3730.51files/s]\u001b[A\n",
      " 25%|██▌       | 52951/210001 [00:21<00:42, 3705.45files/s]\u001b[A\n",
      " 25%|██▌       | 53322/210001 [00:21<00:42, 3701.94files/s]\u001b[A\n",
      " 26%|██▌       | 53693/210001 [00:21<00:42, 3701.20files/s]\u001b[A\n",
      " 26%|██▌       | 54064/210001 [00:21<00:42, 3642.61files/s]\u001b[A\n",
      " 26%|██▌       | 54429/210001 [00:22<00:44, 3489.11files/s]\u001b[A\n",
      " 26%|██▌       | 54784/210001 [00:22<00:44, 3505.18files/s]\u001b[A\n",
      " 26%|██▋       | 55155/210001 [00:22<00:43, 3562.42files/s]\u001b[A\n",
      " 26%|██▋       | 55513/210001 [00:22<00:53, 2878.22files/s]\u001b[A\n",
      " 27%|██▋       | 55823/210001 [00:22<00:56, 2735.59files/s]\u001b[A\n",
      " 27%|██▋       | 56114/210001 [00:22<01:01, 2506.84files/s]\u001b[A\n",
      " 27%|██▋       | 56381/210001 [00:22<01:09, 2201.29files/s]\u001b[A\n",
      " 27%|██▋       | 56619/210001 [00:22<01:10, 2179.44files/s]\u001b[A\n",
      " 27%|██▋       | 56850/210001 [00:23<01:13, 2069.86files/s]\u001b[A\n",
      " 27%|██▋       | 57089/210001 [00:23<01:11, 2149.31files/s]\u001b[A\n",
      " 27%|██▋       | 57312/210001 [00:23<01:14, 2051.47files/s]\u001b[A\n",
      " 27%|██▋       | 57528/210001 [00:23<01:13, 2081.80files/s]\u001b[A\n",
      " 28%|██▊       | 57761/210001 [00:23<01:10, 2149.30files/s]\u001b[A\n",
      " 28%|██▊       | 57980/210001 [00:23<01:16, 1980.39files/s]\u001b[A\n",
      " 28%|██▊       | 58223/210001 [00:23<01:12, 2095.88files/s]\u001b[A\n",
      " 28%|██▊       | 58448/210001 [00:23<01:10, 2139.41files/s]\u001b[A\n",
      " 28%|██▊       | 58666/210001 [00:23<01:15, 2003.45files/s]\u001b[A\n",
      " 28%|██▊       | 58917/210001 [00:24<01:10, 2131.57files/s]\u001b[A\n",
      " 28%|██▊       | 59174/210001 [00:24<01:07, 2245.94files/s]\u001b[A\n",
      " 28%|██▊       | 59418/210001 [00:24<01:05, 2298.98files/s]\u001b[A\n",
      " 28%|██▊       | 59653/210001 [00:24<01:10, 2134.06files/s]\u001b[A\n",
      " 29%|██▊       | 59936/210001 [00:24<01:05, 2300.55files/s]\u001b[A\n",
      " 29%|██▊       | 60309/210001 [00:24<00:57, 2598.34files/s]\u001b[A\n",
      " 29%|██▉       | 60681/210001 [00:24<00:52, 2855.78files/s]\u001b[A\n",
      " 29%|██▉       | 61064/210001 [00:24<00:48, 3090.58files/s]\u001b[A\n",
      " 29%|██▉       | 61436/210001 [00:24<00:45, 3254.40files/s]\u001b[A\n",
      " 29%|██▉       | 61779/210001 [00:24<00:44, 3303.03files/s]\u001b[A\n",
      " 30%|██▉       | 62121/210001 [00:25<00:45, 3273.64files/s]\u001b[A\n",
      " 30%|██▉       | 62480/210001 [00:25<00:43, 3358.95files/s]\u001b[A\n",
      " 30%|██▉       | 62834/210001 [00:25<00:43, 3409.35files/s]\u001b[A\n",
      " 30%|███       | 63180/210001 [00:25<00:49, 2938.86files/s]\u001b[A\n",
      " 30%|███       | 63555/210001 [00:25<00:46, 3142.39files/s]\u001b[A\n",
      " 30%|███       | 63936/210001 [00:25<00:44, 3315.65files/s]\u001b[A\n",
      " 31%|███       | 64317/210001 [00:25<00:42, 3448.66files/s]\u001b[A\n",
      " 31%|███       | 64681/210001 [00:25<00:41, 3501.85files/s]\u001b[A\n",
      " 31%|███       | 65039/210001 [00:26<00:56, 2584.99files/s]\u001b[A\n",
      " 31%|███       | 65338/210001 [00:26<00:54, 2678.29files/s]\u001b[A\n",
      " 31%|███▏      | 65719/210001 [00:26<00:49, 2937.35files/s]\u001b[A\n",
      " 31%|███▏      | 66102/210001 [00:26<00:45, 3157.34files/s]\u001b[A\n",
      " 32%|███▏      | 66442/210001 [00:26<01:07, 2138.72files/s]\u001b[A\n",
      " 32%|███▏      | 66735/210001 [00:26<01:01, 2326.82files/s]\u001b[A\n",
      " 32%|███▏      | 67033/210001 [00:26<00:57, 2489.04files/s]\u001b[A\n",
      " 32%|███▏      | 67319/210001 [00:26<00:55, 2588.61files/s]\u001b[A\n",
      " 32%|███▏      | 67698/210001 [00:27<00:49, 2859.25files/s]\u001b[A\n",
      " 32%|███▏      | 68074/210001 [00:27<00:46, 3080.65files/s]\u001b[A\n",
      " 33%|███▎      | 68452/210001 [00:27<00:43, 3260.09files/s]\u001b[A\n",
      " 33%|███▎      | 68837/210001 [00:27<00:41, 3416.72files/s]\u001b[A\n",
      " 33%|███▎      | 69229/210001 [00:27<00:39, 3553.41files/s]\u001b[A\n",
      " 33%|███▎      | 69612/210001 [00:27<00:38, 3630.69files/s]\u001b[A\n",
      " 33%|███▎      | 69985/210001 [00:27<00:40, 3419.12files/s]\u001b[A\n",
      " 34%|███▎      | 70365/210001 [00:27<00:39, 3522.67files/s]\u001b[A\n",
      " 34%|███▎      | 70738/210001 [00:27<00:38, 3580.87files/s]\u001b[A\n",
      " 34%|███▍      | 71104/210001 [00:27<00:38, 3602.08files/s]\u001b[A\n",
      " 34%|███▍      | 71468/210001 [00:28<00:39, 3500.26files/s]\u001b[A\n",
      " 34%|███▍      | 71822/210001 [00:28<00:41, 3357.94files/s]\u001b[A\n",
      " 34%|███▍      | 72162/210001 [00:28<01:02, 2199.03files/s]\u001b[A\n",
      " 34%|███▍      | 72437/210001 [00:28<01:09, 1985.67files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 72678/210001 [00:28<01:09, 1969.30files/s]\u001b[A\n",
      " 35%|███▍      | 73033/210001 [00:28<01:00, 2272.40files/s]\u001b[A\n",
      " 35%|███▍      | 73345/210001 [00:28<00:55, 2473.51files/s]\u001b[A\n",
      " 35%|███▌      | 73694/210001 [00:29<00:50, 2709.46files/s]\u001b[A\n",
      " 35%|███▌      | 74044/210001 [00:29<00:46, 2905.11files/s]\u001b[A\n",
      " 35%|███▌      | 74359/210001 [00:29<00:46, 2915.18files/s]\u001b[A\n",
      " 36%|███▌      | 74727/210001 [00:29<00:43, 3104.08files/s]\u001b[A\n",
      " 36%|███▌      | 75112/210001 [00:29<00:40, 3293.74files/s]\u001b[A\n",
      " 36%|███▌      | 75477/210001 [00:29<00:39, 3391.89files/s]\u001b[A\n",
      " 36%|███▌      | 75849/210001 [00:29<00:38, 3483.67files/s]\u001b[A\n",
      " 36%|███▋      | 76227/210001 [00:29<00:37, 3567.36files/s]\u001b[A\n",
      " 36%|███▋      | 76604/210001 [00:29<00:36, 3624.04files/s]\u001b[A\n",
      " 37%|███▋      | 77005/210001 [00:29<00:35, 3729.63files/s]\u001b[A\n",
      " 37%|███▋      | 77382/210001 [00:30<00:36, 3679.98files/s]\u001b[A\n",
      " 37%|███▋      | 77753/210001 [00:30<00:36, 3632.38files/s]\u001b[A\n",
      " 37%|███▋      | 78127/210001 [00:30<00:35, 3663.85files/s]\u001b[A\n",
      " 37%|███▋      | 78506/210001 [00:30<00:35, 3699.92files/s]\u001b[A\n",
      " 38%|███▊      | 78878/210001 [00:30<00:35, 3688.55files/s]\u001b[A\n",
      " 38%|███▊      | 79248/210001 [00:30<00:45, 2876.90files/s]\u001b[A\n",
      " 38%|███▊      | 79616/210001 [00:30<00:42, 3078.33files/s]\u001b[A\n",
      " 38%|███▊      | 79985/210001 [00:30<00:40, 3234.26files/s]\u001b[A\n",
      " 38%|███▊      | 80328/210001 [00:31<00:46, 2793.82files/s]\u001b[A\n",
      " 38%|███▊      | 80632/210001 [00:31<00:50, 2577.96files/s]\u001b[A\n",
      " 39%|███▊      | 80910/210001 [00:31<00:50, 2542.46files/s]\u001b[A\n",
      " 39%|███▊      | 81179/210001 [00:31<00:50, 2549.23files/s]\u001b[A\n",
      " 39%|███▉      | 81462/210001 [00:31<00:48, 2625.23files/s]\u001b[A\n",
      " 39%|███▉      | 81803/210001 [00:31<00:45, 2819.83files/s]\u001b[A\n",
      " 39%|███▉      | 82155/210001 [00:31<00:42, 2997.64files/s]\u001b[A\n",
      " 39%|███▉      | 82465/210001 [00:31<00:49, 2564.95files/s]\u001b[A\n",
      " 39%|███▉      | 82743/210001 [00:31<00:48, 2624.67files/s]\u001b[A\n",
      " 40%|███▉      | 83143/210001 [00:32<00:43, 2925.62files/s]\u001b[A\n",
      " 40%|███▉      | 83519/210001 [00:32<00:40, 3132.95files/s]\u001b[A\n",
      " 40%|███▉      | 83905/210001 [00:32<00:37, 3318.61files/s]\u001b[A\n",
      " 40%|████      | 84253/210001 [00:32<00:38, 3283.08files/s]\u001b[A\n",
      " 40%|████      | 84593/210001 [00:32<00:37, 3304.26files/s]\u001b[A\n",
      " 40%|████      | 84932/210001 [00:32<00:38, 3226.68files/s]\u001b[A\n",
      " 41%|████      | 85289/210001 [00:32<00:37, 3319.61files/s]\u001b[A\n",
      " 41%|████      | 85652/210001 [00:32<00:36, 3406.50files/s]\u001b[A\n",
      " 41%|████      | 86025/210001 [00:32<00:35, 3496.76files/s]\u001b[A\n",
      " 41%|████      | 86389/210001 [00:33<00:34, 3536.38files/s]\u001b[A\n",
      " 41%|████▏     | 86746/210001 [00:33<00:37, 3328.30files/s]\u001b[A\n",
      " 41%|████▏     | 87115/210001 [00:33<00:36, 3412.61files/s]\u001b[A\n",
      " 42%|████▏     | 87475/210001 [00:33<00:35, 3464.19files/s]\u001b[A\n",
      " 42%|████▏     | 87860/210001 [00:33<00:34, 3569.70files/s]\u001b[A\n",
      " 42%|████▏     | 88245/210001 [00:33<00:33, 3647.96files/s]\u001b[A\n",
      " 42%|████▏     | 88613/210001 [00:33<00:34, 3561.14files/s]\u001b[A\n",
      " 42%|████▏     | 88993/210001 [00:33<00:33, 3627.89files/s]\u001b[A\n",
      " 43%|████▎     | 89358/210001 [00:33<00:33, 3605.63files/s]\u001b[A\n",
      " 43%|████▎     | 89720/210001 [00:33<00:34, 3530.95files/s]\u001b[A\n",
      " 43%|████▎     | 90079/210001 [00:34<00:33, 3545.21files/s]\u001b[A\n",
      " 43%|████▎     | 90435/210001 [00:34<00:37, 3225.28files/s]\u001b[A\n",
      " 43%|████▎     | 90799/210001 [00:34<00:35, 3333.35files/s]\u001b[A\n",
      " 43%|████▎     | 91138/210001 [00:34<00:39, 3018.60files/s]\u001b[A\n",
      " 44%|████▎     | 91509/210001 [00:34<00:37, 3196.33files/s]\u001b[A\n",
      " 44%|████▍     | 91897/210001 [00:34<00:35, 3373.13files/s]\u001b[A\n",
      " 44%|████▍     | 92244/210001 [00:34<00:35, 3350.97files/s]\u001b[A\n",
      " 44%|████▍     | 92634/210001 [00:34<00:33, 3498.44files/s]\u001b[A\n",
      " 44%|████▍     | 93006/210001 [00:34<00:32, 3561.86files/s]\u001b[A\n",
      " 44%|████▍     | 93368/210001 [00:35<00:32, 3578.50files/s]\u001b[A\n",
      " 45%|████▍     | 93751/210001 [00:35<00:31, 3647.22files/s]\u001b[A\n",
      " 45%|████▍     | 94119/210001 [00:35<00:31, 3648.33files/s]\u001b[A\n",
      " 45%|████▍     | 94486/210001 [00:35<00:31, 3616.33files/s]\u001b[A\n",
      " 45%|████▌     | 94849/210001 [00:35<00:32, 3594.31files/s]\u001b[A\n",
      " 45%|████▌     | 95239/210001 [00:35<00:31, 3679.16files/s]\u001b[A\n",
      " 46%|████▌     | 95609/210001 [00:35<00:31, 3620.71files/s]\u001b[A\n",
      " 46%|████▌     | 95995/210001 [00:35<00:30, 3687.05files/s]\u001b[A\n",
      " 46%|████▌     | 96365/210001 [00:35<00:30, 3686.43files/s]\u001b[A\n",
      " 46%|████▌     | 96735/210001 [00:35<00:30, 3687.25files/s]\u001b[A\n",
      " 46%|████▌     | 97114/210001 [00:36<00:30, 3715.12files/s]\u001b[A\n",
      " 46%|████▋     | 97502/210001 [00:36<00:29, 3763.06files/s]\u001b[A\n",
      " 47%|████▋     | 97892/210001 [00:36<00:29, 3798.38files/s]\u001b[A\n",
      " 47%|████▋     | 98277/210001 [00:36<00:29, 3813.24files/s]\u001b[A\n",
      " 47%|████▋     | 98669/210001 [00:36<00:28, 3842.42files/s]\u001b[A\n",
      " 47%|████▋     | 99057/210001 [00:36<00:28, 3852.28files/s]\u001b[A\n",
      " 47%|████▋     | 99443/210001 [00:36<00:28, 3839.14files/s]\u001b[A\n",
      " 48%|████▊     | 99828/210001 [00:36<00:29, 3749.28files/s]\u001b[A\n",
      " 48%|████▊     | 100212/210001 [00:36<00:29, 3775.45files/s]\u001b[A\n",
      " 48%|████▊     | 100602/210001 [00:36<00:28, 3809.87files/s]\u001b[A\n",
      " 48%|████▊     | 100989/210001 [00:37<00:28, 3825.65files/s]\u001b[A\n",
      " 48%|████▊     | 101378/210001 [00:37<00:28, 3842.46files/s]\u001b[A\n",
      " 48%|████▊     | 101763/210001 [00:37<00:28, 3843.52files/s]\u001b[A\n",
      " 49%|████▊     | 102148/210001 [00:37<00:28, 3837.96files/s]\u001b[A\n",
      " 49%|████▉     | 102532/210001 [00:37<00:28, 3825.12files/s]\u001b[A\n",
      " 49%|████▉     | 102923/210001 [00:37<00:27, 3850.18files/s]\u001b[A\n",
      " 49%|████▉     | 103310/210001 [00:37<00:27, 3854.42files/s]\u001b[A\n",
      " 49%|████▉     | 103696/210001 [00:37<00:27, 3846.60files/s]\u001b[A\n",
      " 50%|████▉     | 104081/210001 [00:37<00:27, 3829.63files/s]\u001b[A\n",
      " 50%|████▉     | 104471/210001 [00:37<00:27, 3849.08files/s]\u001b[A\n",
      " 50%|████▉     | 104861/210001 [00:38<00:27, 3863.80files/s]\u001b[A\n",
      " 50%|█████     | 105251/210001 [00:38<00:27, 3874.39files/s]\u001b[A\n",
      " 50%|█████     | 105639/210001 [00:38<00:26, 3867.54files/s]\u001b[A\n",
      " 50%|█████     | 106035/210001 [00:38<00:26, 3893.40files/s]\u001b[A\n",
      " 51%|█████     | 106429/210001 [00:38<00:26, 3907.01files/s]\u001b[A\n",
      " 51%|█████     | 106820/210001 [00:38<00:26, 3892.87files/s]\u001b[A\n",
      " 51%|█████     | 107210/210001 [00:38<00:26, 3841.43files/s]\u001b[A\n",
      " 51%|█████     | 107595/210001 [00:38<00:26, 3810.44files/s]\u001b[A\n",
      " 51%|█████▏    | 107991/210001 [00:38<00:26, 3852.34files/s]\u001b[A\n",
      " 52%|█████▏    | 108377/210001 [00:39<00:30, 3373.62files/s]\u001b[A\n",
      " 52%|█████▏    | 108726/210001 [00:39<00:31, 3253.81files/s]\u001b[A\n",
      " 52%|█████▏    | 109129/210001 [00:39<00:29, 3452.55files/s]\u001b[A\n",
      " 52%|█████▏    | 109497/210001 [00:39<00:28, 3515.93files/s]\u001b[A\n",
      " 52%|█████▏    | 109884/210001 [00:39<00:27, 3613.57files/s]\u001b[A\n",
      " 53%|█████▎    | 110275/210001 [00:39<00:26, 3696.40files/s]\u001b[A\n",
      " 53%|█████▎    | 110675/210001 [00:39<00:26, 3781.63files/s]\u001b[A\n",
      " 53%|█████▎    | 111064/210001 [00:39<00:25, 3811.96files/s]\u001b[A\n",
      " 53%|█████▎    | 111474/210001 [00:39<00:25, 3892.01files/s]\u001b[A\n",
      " 53%|█████▎    | 111866/210001 [00:39<00:25, 3860.95files/s]\u001b[A\n",
      " 53%|█████▎    | 112254/210001 [00:40<00:25, 3826.61files/s]\u001b[A\n",
      " 54%|█████▎    | 112638/210001 [00:40<00:27, 3534.24files/s]\u001b[A\n",
      " 54%|█████▍    | 113011/210001 [00:40<00:27, 3590.21files/s]\u001b[A\n",
      " 54%|█████▍    | 113405/210001 [00:40<00:26, 3688.12files/s]\u001b[A\n",
      " 54%|█████▍    | 113798/210001 [00:40<00:25, 3757.18files/s]\u001b[A\n",
      " 54%|█████▍    | 114182/210001 [00:40<00:25, 3780.91files/s]\u001b[A\n",
      " 55%|█████▍    | 114563/210001 [00:40<00:25, 3707.17files/s]\u001b[A\n",
      " 55%|█████▍    | 114936/210001 [00:40<00:27, 3496.34files/s]\u001b[A\n",
      " 55%|█████▍    | 115290/210001 [00:40<00:27, 3388.27files/s]\u001b[A\n",
      " 55%|█████▌    | 115687/210001 [00:41<00:26, 3542.29files/s]\u001b[A\n",
      " 55%|█████▌    | 116054/210001 [00:41<00:26, 3577.76files/s]\u001b[A\n",
      " 55%|█████▌    | 116415/210001 [00:41<00:28, 3322.64files/s]\u001b[A\n",
      " 56%|█████▌    | 116806/210001 [00:41<00:26, 3478.56files/s]\u001b[A\n",
      " 56%|█████▌    | 117202/210001 [00:41<00:25, 3609.38files/s]\u001b[A\n",
      " 56%|█████▌    | 117596/210001 [00:41<00:24, 3700.25files/s]\u001b[A\n",
      " 56%|█████▌    | 117976/210001 [00:41<00:24, 3727.43files/s]\u001b[A\n",
      " 56%|█████▋    | 118367/210001 [00:41<00:24, 3779.19files/s]\u001b[A\n",
      " 57%|█████▋    | 118748/210001 [00:41<00:24, 3730.76files/s]\u001b[A\n",
      " 57%|█████▋    | 119123/210001 [00:41<00:24, 3686.14files/s]\u001b[A\n",
      " 57%|█████▋    | 119493/210001 [00:42<00:24, 3687.11files/s]\u001b[A\n",
      " 57%|█████▋    | 119863/210001 [00:42<00:24, 3677.19files/s]\u001b[A\n",
      " 57%|█████▋    | 120238/210001 [00:42<00:24, 3696.83files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 120616/210001 [00:42<00:24, 3720.43files/s]\u001b[A\n",
      " 58%|█████▊    | 120989/210001 [00:42<00:24, 3702.78files/s]\u001b[A\n",
      " 58%|█████▊    | 121360/210001 [00:42<00:23, 3703.12files/s]\u001b[A\n",
      " 58%|█████▊    | 121731/210001 [00:42<00:23, 3696.23files/s]\u001b[A\n",
      " 58%|█████▊    | 122110/210001 [00:42<00:23, 3721.59files/s]\u001b[A\n",
      " 58%|█████▊    | 122483/210001 [00:42<00:24, 3528.49files/s]\u001b[A\n",
      " 59%|█████▊    | 122860/210001 [00:42<00:24, 3595.91files/s]\u001b[A\n",
      " 59%|█████▊    | 123228/210001 [00:43<00:23, 3620.08files/s]\u001b[A\n",
      " 59%|█████▉    | 123609/210001 [00:43<00:23, 3674.81files/s]\u001b[A\n",
      " 59%|█████▉    | 123991/210001 [00:43<00:23, 3717.00files/s]\u001b[A\n",
      " 59%|█████▉    | 124364/210001 [00:43<00:23, 3618.03files/s]\u001b[A\n",
      " 59%|█████▉    | 124755/210001 [00:43<00:23, 3698.59files/s]\u001b[A\n",
      " 60%|█████▉    | 125148/210001 [00:43<00:22, 3763.24files/s]\u001b[A\n",
      " 60%|█████▉    | 125537/210001 [00:43<00:22, 3797.70files/s]\u001b[A\n",
      " 60%|█████▉    | 125934/210001 [00:43<00:21, 3847.66files/s]\u001b[A\n",
      " 60%|██████    | 126320/210001 [00:43<00:22, 3641.26files/s]\u001b[A\n",
      " 60%|██████    | 126687/210001 [00:43<00:22, 3644.87files/s]\u001b[A\n",
      " 61%|██████    | 127054/210001 [00:44<00:22, 3638.99files/s]\u001b[A\n",
      " 61%|██████    | 127428/210001 [00:44<00:22, 3667.52files/s]\u001b[A\n",
      " 61%|██████    | 127796/210001 [00:44<00:22, 3667.57files/s]\u001b[A\n",
      " 61%|██████    | 128165/210001 [00:44<00:22, 3673.23files/s]\u001b[A\n",
      " 61%|██████    | 128552/210001 [00:44<00:21, 3727.76files/s]\u001b[A\n",
      " 61%|██████▏   | 128926/210001 [00:44<00:21, 3714.02files/s]\u001b[A\n",
      " 62%|██████▏   | 129322/210001 [00:44<00:21, 3779.85files/s]\u001b[A\n",
      " 62%|██████▏   | 129701/210001 [00:44<00:21, 3776.47files/s]\u001b[A\n",
      " 62%|██████▏   | 130080/210001 [00:44<00:21, 3734.22files/s]\u001b[A\n",
      " 62%|██████▏   | 130466/210001 [00:45<00:21, 3770.61files/s]\u001b[A\n",
      " 62%|██████▏   | 130844/210001 [00:45<00:21, 3726.53files/s]\u001b[A\n",
      " 62%|██████▏   | 131218/210001 [00:45<00:21, 3658.90files/s]\u001b[A\n",
      " 63%|██████▎   | 131600/210001 [00:45<00:21, 3703.21files/s]\u001b[A\n",
      " 63%|██████▎   | 131985/210001 [00:45<00:20, 3744.46files/s]\u001b[A\n",
      " 63%|██████▎   | 132370/210001 [00:45<00:20, 3772.82files/s]\u001b[A\n",
      " 63%|██████▎   | 132748/210001 [00:45<00:23, 3335.03files/s]\u001b[A\n",
      " 63%|██████▎   | 133124/210001 [00:45<00:22, 3450.78files/s]\u001b[A\n",
      " 64%|██████▎   | 133516/210001 [00:45<00:21, 3578.36files/s]\u001b[A\n",
      " 64%|██████▍   | 133885/210001 [00:45<00:21, 3610.08files/s]\u001b[A\n",
      " 64%|██████▍   | 134262/210001 [00:46<00:20, 3656.61files/s]\u001b[A\n",
      " 64%|██████▍   | 134640/210001 [00:46<00:20, 3690.43files/s]\u001b[A\n",
      " 64%|██████▍   | 135022/210001 [00:46<00:20, 3727.03files/s]\u001b[A\n",
      " 64%|██████▍   | 135403/210001 [00:46<00:19, 3748.69files/s]\u001b[A\n",
      " 65%|██████▍   | 135799/210001 [00:46<00:19, 3808.37files/s]\u001b[A\n",
      " 65%|██████▍   | 136181/210001 [00:46<00:19, 3760.53files/s]\u001b[A\n",
      " 65%|██████▌   | 136558/210001 [00:46<00:20, 3644.28files/s]\u001b[A\n",
      " 65%|██████▌   | 136924/210001 [00:46<00:20, 3574.80files/s]\u001b[A\n",
      " 65%|██████▌   | 137287/210001 [00:46<00:20, 3589.18files/s]\u001b[A\n",
      " 66%|██████▌   | 137647/210001 [00:47<00:21, 3380.90files/s]\u001b[A\n",
      " 66%|██████▌   | 137989/210001 [00:47<00:21, 3367.74files/s]\u001b[A\n",
      " 66%|██████▌   | 138357/210001 [00:47<00:20, 3454.63files/s]\u001b[A\n",
      " 66%|██████▌   | 138729/210001 [00:47<00:20, 3528.64files/s]\u001b[A\n",
      " 66%|██████▌   | 139084/210001 [00:47<00:23, 3078.41files/s]\u001b[A\n",
      " 66%|██████▋   | 139445/210001 [00:47<00:21, 3220.04files/s]\u001b[A\n",
      " 67%|██████▋   | 139777/210001 [00:47<00:22, 3083.85files/s]\u001b[A\n",
      " 67%|██████▋   | 140094/210001 [00:47<00:23, 3003.44files/s]\u001b[A\n",
      " 67%|██████▋   | 140401/210001 [00:47<00:23, 3014.08files/s]\u001b[A\n",
      " 67%|██████▋   | 140776/210001 [00:47<00:21, 3201.48files/s]\u001b[A\n",
      " 67%|██████▋   | 141141/210001 [00:48<00:20, 3322.17files/s]\u001b[A\n",
      " 67%|██████▋   | 141514/210001 [00:48<00:19, 3432.81files/s]\u001b[A\n",
      " 68%|██████▊   | 141911/210001 [00:48<00:19, 3577.19files/s]\u001b[A\n",
      " 68%|██████▊   | 142299/210001 [00:48<00:18, 3662.13files/s]\u001b[A\n",
      " 68%|██████▊   | 142690/210001 [00:48<00:18, 3731.44files/s]\u001b[A\n",
      " 68%|██████▊   | 143070/210001 [00:48<00:17, 3750.45files/s]\u001b[A\n",
      " 68%|██████▊   | 143448/210001 [00:48<00:17, 3707.27files/s]\u001b[A\n",
      " 68%|██████▊   | 143821/210001 [00:48<00:17, 3700.12files/s]\u001b[A\n",
      " 69%|██████▊   | 144194/210001 [00:48<00:17, 3706.73files/s]\u001b[A\n",
      " 69%|██████▉   | 144566/210001 [00:49<00:17, 3659.65files/s]\u001b[A\n",
      " 69%|██████▉   | 144950/210001 [00:49<00:17, 3711.71files/s]\u001b[A\n",
      " 69%|██████▉   | 145323/210001 [00:49<00:17, 3715.95files/s]\u001b[A\n",
      " 69%|██████▉   | 145696/210001 [00:49<00:17, 3682.74files/s]\u001b[A\n",
      " 70%|██████▉   | 146065/210001 [00:49<00:18, 3545.09files/s]\u001b[A\n",
      " 70%|██████▉   | 146421/210001 [00:49<00:18, 3453.35files/s]\u001b[A\n",
      " 70%|██████▉   | 146793/210001 [00:49<00:17, 3528.90files/s]\u001b[A\n",
      " 70%|███████   | 147186/210001 [00:49<00:17, 3638.77files/s]\u001b[A\n",
      " 70%|███████   | 147572/210001 [00:49<00:16, 3700.07files/s]\u001b[A\n",
      " 70%|███████   | 147967/210001 [00:49<00:16, 3770.20files/s]\u001b[A\n",
      " 71%|███████   | 148360/210001 [00:50<00:16, 3814.50files/s]\u001b[A\n",
      " 71%|███████   | 148755/210001 [00:50<00:15, 3852.63files/s]\u001b[A\n",
      " 71%|███████   | 149142/210001 [00:50<00:15, 3853.97files/s]\u001b[A\n",
      " 71%|███████   | 149531/210001 [00:50<00:15, 3863.27files/s]\u001b[A\n",
      " 71%|███████▏  | 149918/210001 [00:50<00:15, 3851.88files/s]\u001b[A\n",
      " 72%|███████▏  | 150304/210001 [00:50<00:15, 3830.76files/s]\u001b[A\n",
      " 72%|███████▏  | 150688/210001 [00:50<00:15, 3823.98files/s]\u001b[A\n",
      " 72%|███████▏  | 151071/210001 [00:50<00:15, 3812.04files/s]\u001b[A\n",
      " 72%|███████▏  | 151454/210001 [00:50<00:15, 3816.17files/s]\u001b[A\n",
      " 72%|███████▏  | 151836/210001 [00:50<00:15, 3800.09files/s]\u001b[A\n",
      " 72%|███████▏  | 152217/210001 [00:51<00:15, 3714.51files/s]\u001b[A\n",
      " 73%|███████▎  | 152605/210001 [00:51<00:15, 3761.98files/s]\u001b[A\n",
      " 73%|███████▎  | 152990/210001 [00:51<00:15, 3786.06files/s]\u001b[A\n",
      " 73%|███████▎  | 153381/210001 [00:51<00:14, 3820.25files/s]\u001b[A\n",
      " 73%|███████▎  | 153765/210001 [00:51<00:14, 3824.79files/s]\u001b[A\n",
      " 73%|███████▎  | 154150/210001 [00:51<00:14, 3831.34files/s]\u001b[A\n",
      " 74%|███████▎  | 154534/210001 [00:51<00:14, 3778.74files/s]\u001b[A\n",
      " 74%|███████▍  | 154931/210001 [00:51<00:14, 3829.55files/s]\u001b[A\n",
      " 74%|███████▍  | 155322/210001 [00:51<00:14, 3853.33files/s]\u001b[A\n",
      " 74%|███████▍  | 155708/210001 [00:51<00:14, 3799.79files/s]\u001b[A\n",
      " 74%|███████▍  | 156089/210001 [00:52<00:14, 3740.90files/s]\u001b[A\n",
      " 75%|███████▍  | 156472/210001 [00:52<00:14, 3763.04files/s]\u001b[A\n",
      " 75%|███████▍  | 156861/210001 [00:52<00:13, 3799.52files/s]\u001b[A\n",
      " 75%|███████▍  | 157242/210001 [00:52<00:14, 3748.27files/s]\u001b[A\n",
      " 75%|███████▌  | 157629/210001 [00:52<00:13, 3782.57files/s]\u001b[A\n",
      " 75%|███████▌  | 158008/210001 [00:52<00:14, 3486.22files/s]\u001b[A\n",
      " 75%|███████▌  | 158362/210001 [00:52<00:15, 3422.95files/s]\u001b[A\n",
      " 76%|███████▌  | 158751/210001 [00:52<00:14, 3549.13files/s]\u001b[A\n",
      " 76%|███████▌  | 159136/210001 [00:52<00:13, 3633.57files/s]\u001b[A\n",
      " 76%|███████▌  | 159519/210001 [00:53<00:13, 3690.09files/s]\u001b[A\n",
      " 76%|███████▌  | 159912/210001 [00:53<00:13, 3757.00files/s]\u001b[A\n",
      " 76%|███████▋  | 160290/210001 [00:53<00:13, 3714.22files/s]\u001b[A\n",
      " 77%|███████▋  | 160699/210001 [00:53<00:12, 3816.01files/s]\u001b[A\n",
      " 77%|███████▋  | 161083/210001 [00:53<00:12, 3816.93files/s]\u001b[A\n",
      " 77%|███████▋  | 161478/210001 [00:53<00:12, 3852.84files/s]\u001b[A\n",
      " 77%|███████▋  | 161865/210001 [00:53<00:12, 3830.15files/s]\u001b[A\n",
      " 77%|███████▋  | 162257/210001 [00:53<00:12, 3856.18files/s]\u001b[A\n",
      " 77%|███████▋  | 162650/210001 [00:53<00:12, 3876.14files/s]\u001b[A\n",
      " 78%|███████▊  | 163048/210001 [00:53<00:12, 3904.84files/s]\u001b[A\n",
      " 78%|███████▊  | 163439/210001 [00:54<00:11, 3891.39files/s]\u001b[A\n",
      " 78%|███████▊  | 163840/210001 [00:54<00:11, 3925.74files/s]\u001b[A\n",
      " 78%|███████▊  | 164233/210001 [00:54<00:11, 3891.07files/s]\u001b[A\n",
      " 78%|███████▊  | 164623/210001 [00:54<00:11, 3815.36files/s]\u001b[A\n",
      " 79%|███████▊  | 165006/210001 [00:54<00:11, 3792.23files/s]\u001b[A\n",
      " 79%|███████▉  | 165402/210001 [00:54<00:11, 3836.67files/s]\u001b[A\n",
      " 79%|███████▉  | 165791/210001 [00:54<00:11, 3851.75files/s]\u001b[A\n",
      " 79%|███████▉  | 166177/210001 [00:54<00:11, 3848.74files/s]\u001b[A\n",
      " 79%|███████▉  | 166563/210001 [00:54<00:11, 3817.34files/s]\u001b[A\n",
      " 80%|███████▉  | 166953/210001 [00:54<00:11, 3839.78files/s]\u001b[A\n",
      " 80%|███████▉  | 167354/210001 [00:55<00:10, 3888.38files/s]\u001b[A\n",
      " 80%|███████▉  | 167744/210001 [00:55<00:10, 3862.92files/s]\u001b[A\n",
      " 80%|████████  | 168132/210001 [00:55<00:10, 3867.37files/s]\u001b[A\n",
      " 80%|████████  | 168519/210001 [00:55<00:10, 3844.29files/s]\u001b[A\n",
      " 80%|████████  | 168916/210001 [00:55<00:10, 3881.03files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 169321/210001 [00:55<00:10, 3929.72files/s]\u001b[A\n",
      " 81%|████████  | 169715/210001 [00:55<00:10, 3841.64files/s]\u001b[A\n",
      " 81%|████████  | 170120/210001 [00:55<00:10, 3895.41files/s]\u001b[A\n",
      " 81%|████████  | 170511/210001 [00:55<00:10, 3856.33files/s]\u001b[A\n",
      " 81%|████████▏ | 170898/210001 [00:55<00:10, 3831.44files/s]\u001b[A\n",
      " 82%|████████▏ | 171302/210001 [00:56<00:09, 3886.60files/s]\u001b[A\n",
      " 82%|████████▏ | 171700/210001 [00:56<00:09, 3912.17files/s]\u001b[A\n",
      " 82%|████████▏ | 172092/210001 [00:56<00:09, 3869.31files/s]\u001b[A\n",
      " 82%|████████▏ | 172480/210001 [00:56<00:09, 3844.56files/s]\u001b[A\n",
      " 82%|████████▏ | 172865/210001 [00:56<00:09, 3799.97files/s]\u001b[A\n",
      " 82%|████████▏ | 173246/210001 [00:56<00:10, 3628.54files/s]\u001b[A\n",
      " 83%|████████▎ | 173637/210001 [00:56<00:09, 3708.03files/s]\u001b[A\n",
      " 83%|████████▎ | 174033/210001 [00:56<00:09, 3778.29files/s]\u001b[A\n",
      " 83%|████████▎ | 174413/210001 [00:56<00:09, 3771.27files/s]\u001b[A\n",
      " 83%|████████▎ | 174797/210001 [00:56<00:09, 3789.59files/s]\u001b[A\n",
      " 83%|████████▎ | 175187/210001 [00:57<00:09, 3820.80files/s]\u001b[A\n",
      " 84%|████████▎ | 175575/210001 [00:57<00:08, 3838.21files/s]\u001b[A\n",
      " 84%|████████▍ | 175973/210001 [00:57<00:08, 3877.68files/s]\u001b[A\n",
      " 84%|████████▍ | 176362/210001 [00:57<00:08, 3851.19files/s]\u001b[A\n",
      " 84%|████████▍ | 176773/210001 [00:57<00:08, 3924.69files/s]\u001b[A\n",
      " 84%|████████▍ | 177167/210001 [00:57<00:08, 3907.05files/s]\u001b[A\n",
      " 85%|████████▍ | 177569/210001 [00:57<00:08, 3932.13files/s]\u001b[A\n",
      " 85%|████████▍ | 177963/210001 [00:57<00:08, 3919.91files/s]\u001b[A\n",
      " 85%|████████▍ | 178356/210001 [00:57<00:08, 3848.46files/s]\u001b[A\n",
      " 85%|████████▌ | 178755/210001 [00:57<00:08, 3887.28files/s]\u001b[A\n",
      " 85%|████████▌ | 179166/210001 [00:58<00:07, 3950.33files/s]\u001b[A\n",
      " 86%|████████▌ | 179567/210001 [00:58<00:07, 3967.79files/s]\u001b[A\n",
      " 86%|████████▌ | 179967/210001 [00:58<00:07, 3975.59files/s]\u001b[A\n",
      " 86%|████████▌ | 180365/210001 [00:58<00:07, 3970.92files/s]\u001b[A\n",
      " 86%|████████▌ | 180763/210001 [00:58<00:07, 3933.36files/s]\u001b[A\n",
      " 86%|████████▋ | 181157/210001 [00:58<00:07, 3934.72files/s]\u001b[A\n",
      " 86%|████████▋ | 181559/210001 [00:58<00:07, 3959.35files/s]\u001b[A\n",
      " 87%|████████▋ | 181965/210001 [00:58<00:07, 3988.41files/s]\u001b[A\n",
      " 87%|████████▋ | 182364/210001 [00:58<00:07, 3928.03files/s]\u001b[A\n",
      " 87%|████████▋ | 182777/210001 [00:59<00:06, 3984.70files/s]\u001b[A\n",
      " 87%|████████▋ | 183176/210001 [00:59<00:06, 3982.84files/s]\u001b[A\n",
      " 87%|████████▋ | 183575/210001 [00:59<00:06, 3931.97files/s]\u001b[A\n",
      " 88%|████████▊ | 183987/210001 [00:59<00:06, 3983.06files/s]\u001b[A\n",
      " 88%|████████▊ | 184386/210001 [00:59<00:06, 3960.25files/s]\u001b[A\n",
      " 88%|████████▊ | 184793/210001 [00:59<00:06, 3990.38files/s]\u001b[A\n",
      " 88%|████████▊ | 185193/210001 [00:59<00:06, 3989.62files/s]\u001b[A\n",
      " 88%|████████▊ | 185593/210001 [00:59<00:06, 3964.87files/s]\u001b[A\n",
      " 89%|████████▊ | 185995/210001 [00:59<00:06, 3977.28files/s]\u001b[A\n",
      " 89%|████████▉ | 186395/210001 [00:59<00:05, 3983.02files/s]\u001b[A\n",
      " 89%|████████▉ | 186794/210001 [01:00<00:05, 3964.14files/s]\u001b[A\n",
      " 89%|████████▉ | 187191/210001 [01:00<00:06, 3795.58files/s]\u001b[A\n",
      " 89%|████████▉ | 187580/210001 [01:00<00:05, 3819.58files/s]\u001b[A\n",
      " 90%|████████▉ | 187964/210001 [01:00<00:05, 3782.92files/s]\u001b[A\n",
      " 90%|████████▉ | 188344/210001 [01:00<00:05, 3692.20files/s]\u001b[A\n",
      " 90%|████████▉ | 188715/210001 [01:00<00:05, 3652.28files/s]\u001b[A\n",
      " 90%|█████████ | 189082/210001 [01:00<00:06, 3274.20files/s]\u001b[A\n",
      " 90%|█████████ | 189470/210001 [01:00<00:05, 3434.79files/s]\u001b[A\n",
      " 90%|█████████ | 189874/210001 [01:00<00:05, 3593.87files/s]\u001b[A\n",
      " 91%|█████████ | 190260/210001 [01:00<00:05, 3667.61files/s]\u001b[A\n",
      " 91%|█████████ | 190648/210001 [01:01<00:05, 3726.99files/s]\u001b[A\n",
      " 91%|█████████ | 191050/210001 [01:01<00:04, 3809.43files/s]\u001b[A\n",
      " 91%|█████████ | 191435/210001 [01:01<00:04, 3815.90files/s]\u001b[A\n",
      " 91%|█████████▏| 191824/210001 [01:01<00:04, 3836.39files/s]\u001b[A\n",
      " 92%|█████████▏| 192230/210001 [01:01<00:04, 3899.98files/s]\u001b[A\n",
      " 92%|█████████▏| 192622/210001 [01:01<00:04, 3902.91files/s]\u001b[A\n",
      " 92%|█████████▏| 193014/210001 [01:01<00:04, 3876.92files/s]\u001b[A\n",
      " 92%|█████████▏| 193403/210001 [01:01<00:04, 3832.10files/s]\u001b[A\n",
      " 92%|█████████▏| 193788/210001 [01:01<00:04, 3834.92files/s]\u001b[A\n",
      " 92%|█████████▏| 194194/210001 [01:01<00:04, 3895.54files/s]\u001b[A\n",
      " 93%|█████████▎| 194585/210001 [01:02<00:03, 3859.27files/s]\u001b[A\n",
      " 93%|█████████▎| 194974/210001 [01:02<00:03, 3868.25files/s]\u001b[A\n",
      " 93%|█████████▎| 195362/210001 [01:02<00:04, 3471.85files/s]\u001b[A\n",
      " 93%|█████████▎| 195718/210001 [01:02<00:04, 3495.07files/s]\u001b[A\n",
      " 93%|█████████▎| 196107/210001 [01:02<00:03, 3604.82files/s]\u001b[A\n",
      " 94%|█████████▎| 196482/210001 [01:02<00:03, 3646.73files/s]\u001b[A\n",
      " 94%|█████████▎| 196851/210001 [01:02<00:03, 3587.31files/s]\u001b[A\n",
      " 94%|█████████▍| 197246/210001 [01:02<00:03, 3686.18files/s]\u001b[A\n",
      " 94%|█████████▍| 197618/210001 [01:02<00:03, 3624.74files/s]\u001b[A\n",
      " 94%|█████████▍| 198003/210001 [01:03<00:03, 3679.03files/s]\u001b[A\n",
      " 94%|█████████▍| 198409/210001 [01:03<00:03, 3784.71files/s]\u001b[A\n",
      " 95%|█████████▍| 198809/210001 [01:03<00:02, 3844.55files/s]\u001b[A\n",
      " 95%|█████████▍| 199195/210001 [01:03<00:02, 3846.74files/s]\u001b[A\n",
      " 95%|█████████▌| 199585/210001 [01:03<00:02, 3861.73files/s]\u001b[A\n",
      " 95%|█████████▌| 199983/210001 [01:03<00:02, 3895.46files/s]\u001b[A\n",
      " 95%|█████████▌| 200374/210001 [01:03<00:02, 3895.74files/s]\u001b[A\n",
      " 96%|█████████▌| 200765/210001 [01:03<00:02, 3835.33files/s]\u001b[A\n",
      " 96%|█████████▌| 201150/210001 [01:03<00:02, 3821.96files/s]\u001b[A\n",
      " 96%|█████████▌| 201540/210001 [01:03<00:02, 3844.45files/s]\u001b[A\n",
      " 96%|█████████▌| 201927/210001 [01:04<00:02, 3851.75files/s]\u001b[A\n",
      " 96%|█████████▋| 202316/210001 [01:04<00:01, 3861.21files/s]\u001b[A\n",
      " 97%|█████████▋| 202707/210001 [01:04<00:01, 3875.61files/s]\u001b[A\n",
      " 97%|█████████▋| 203095/210001 [01:04<00:01, 3628.78files/s]\u001b[A\n",
      " 97%|█████████▋| 203492/210001 [01:04<00:01, 3723.09files/s]\u001b[A\n",
      " 97%|█████████▋| 203902/210001 [01:04<00:01, 3826.90files/s]\u001b[A\n",
      " 97%|█████████▋| 204288/210001 [01:04<00:01, 3762.62files/s]\u001b[A\n",
      " 97%|█████████▋| 204694/210001 [01:04<00:01, 3845.50files/s]\u001b[A\n",
      " 98%|█████████▊| 205088/210001 [01:04<00:01, 3871.34files/s]\u001b[A\n",
      " 98%|█████████▊| 205477/210001 [01:04<00:01, 3859.80files/s]\u001b[A\n",
      " 98%|█████████▊| 205881/210001 [01:05<00:01, 3910.05files/s]\u001b[A\n",
      " 98%|█████████▊| 206286/210001 [01:05<00:00, 3949.64files/s]\u001b[A\n",
      " 98%|█████████▊| 206682/210001 [01:05<00:00, 3938.90files/s]\u001b[A\n",
      " 99%|█████████▊| 207093/210001 [01:05<00:00, 3985.95files/s]\u001b[A\n",
      " 99%|█████████▉| 207496/210001 [01:05<00:00, 3996.55files/s]\u001b[A\n",
      " 99%|█████████▉| 207896/210001 [01:05<00:00, 3959.85files/s]\u001b[A\n",
      " 99%|█████████▉| 208293/210001 [01:05<00:00, 3897.03files/s]\u001b[A\n",
      " 99%|█████████▉| 208693/210001 [01:05<00:00, 3925.06files/s]\u001b[A\n",
      "100%|█████████▉| 209088/210001 [01:05<00:00, 3932.13files/s]\u001b[A\n",
      "100%|█████████▉| 209482/210001 [01:06<00:00, 3902.65files/s]\u001b[A\n",
      "100%|█████████▉| 209876/210001 [01:06<00:00, 3913.01files/s]\u001b[A\n",
      "100%|██████████| 210001/210001 [01:06<00:00, 3175.08files/s]\u001b[A\n",
      "  0%|          | 0/10001 [00:00<?, ?files/s]\u001b[A\n",
      "  4%|▍         | 378/10001 [00:00<00:02, 3777.70files/s]\u001b[A\n",
      "  8%|▊         | 787/10001 [00:00<00:02, 3864.02files/s]\u001b[A\n",
      " 12%|█▏        | 1186/10001 [00:00<00:02, 3900.00files/s]\u001b[A\n",
      " 16%|█▌        | 1600/10001 [00:00<00:02, 3968.88files/s]\u001b[A\n",
      " 20%|█▉        | 1991/10001 [00:00<00:02, 3948.13files/s]\u001b[A\n",
      " 24%|██▍       | 2387/10001 [00:00<00:01, 3950.80files/s]\u001b[A\n",
      " 28%|██▊       | 2767/10001 [00:00<00:01, 3904.28files/s]\u001b[A\n",
      " 31%|███▏      | 3143/10001 [00:00<00:01, 3858.78files/s]\u001b[A\n",
      " 35%|███▌      | 3533/10001 [00:00<00:01, 3869.74files/s]\u001b[A\n",
      " 39%|███▉      | 3909/10001 [00:01<00:01, 3834.75files/s]\u001b[A\n",
      " 43%|████▎     | 4285/10001 [00:01<00:01, 3809.83files/s]\u001b[A\n",
      " 47%|████▋     | 4659/10001 [00:01<00:01, 3709.09files/s]\u001b[A\n",
      " 50%|█████     | 5032/10001 [00:01<00:01, 3713.61files/s]\u001b[A\n",
      " 54%|█████▍    | 5401/10001 [00:01<00:01, 3631.28files/s]\u001b[A\n",
      " 58%|█████▊    | 5763/10001 [00:01<00:01, 3086.94files/s]\u001b[A\n",
      " 61%|██████▏   | 6137/10001 [00:01<00:01, 3257.41files/s]\u001b[A\n",
      " 65%|██████▍   | 6475/10001 [00:01<00:01, 3202.29files/s]\u001b[A\n",
      " 68%|██████▊   | 6832/10001 [00:01<00:00, 3301.98files/s]\u001b[A\n",
      " 72%|███████▏  | 7169/10001 [00:01<00:00, 3215.08files/s]\u001b[A\n",
      " 75%|███████▌  | 7537/10001 [00:02<00:00, 3340.77files/s]\u001b[A\n",
      " 79%|███████▉  | 7922/10001 [00:02<00:00, 3475.71files/s]\u001b[A\n",
      " 83%|████████▎ | 8303/10001 [00:02<00:00, 3567.69files/s]\u001b[A\n",
      " 87%|████████▋ | 8699/10001 [00:02<00:00, 3674.53files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9095/10001 [00:02<00:00, 3753.91files/s]\u001b[A\n",
      " 95%|█████████▍| 9474/10001 [00:02<00:00, 3741.66files/s]\u001b[A\n",
      " 99%|█████████▉| 9876/10001 [00:02<00:00, 3817.63files/s]\u001b[A\n",
      "100%|██████████| 10001/10001 [00:02<00:00, 3656.80files/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Mean_Variance_Image.png\" style=\"height: 75%;width: 75%; position: relative; right: 5%\">\n",
    "## Problem 1\n",
    "The first problem involves normalizing the features for your training and test data.\n",
    "\n",
    "Implement Min-Max scaling in the `normalize_grayscale()` function to a range of `a=0.1` and `b=0.9`. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.\n",
    "\n",
    "Since the raw notMNIST image data is in [grayscale](https://en.wikipedia.org/wiki/Grayscale), the current values range from a min of 0 to a max of 255.\n",
    "\n",
    "Min-Max Scaling:\n",
    "$\n",
    "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
    "$\n",
    "\n",
    "*If you're having trouble solving problem 1, you can view the solution [here](https://github.com/udacity/deep-learning/blob/master/intro-to-tensorflow/intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    return 0.1 + (image_data * 0.8) / 255\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to pickle file...\n",
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "All your progress is now saved to the pickle file.  If you need to leave and comeback to this lab, you no longer have to start from the beginning.  Just run the code block below and it will load all the data and modules required to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2\n",
    "\n",
    "Now it's time to build a simple neural network using TensorFlow. Here, your network will be just an input layer and an output layer.\n",
    "\n",
    "<img src=\"image/network_diagram.png\" style=\"height: 40%;width: 40%; position: relative; right: 10%\">\n",
    "\n",
    "For the input here the images have been flattened into a vector of $28 \\times 28 = 784$ features. Then, we're trying to predict the image digit so there are 10 output units, one for each label. Of course, feel free to add hidden layers if you want, but this notebook is built to guide you through a single layer network. \n",
    "\n",
    "For the neural network to train on your data, you need the following <a href=\"https://www.tensorflow.org/resources/dims_types.html#data-types\">float32</a> tensors:\n",
    " - `features`\n",
    "  - Placeholder tensor for feature data (`train_features`/`valid_features`/`test_features`)\n",
    " - `labels`\n",
    "  - Placeholder tensor for label data (`train_labels`/`valid_labels`/`test_labels`)\n",
    " - `weights`\n",
    "  - Variable Tensor with random numbers from a truncated normal distribution.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#truncated_normal\">`tf.truncated_normal()` documentation</a> for help.\n",
    " - `biases`\n",
    "  - Variable Tensor with all zeros.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#zeros\"> `tf.zeros()` documentation</a> for help.\n",
    "\n",
    "*If you're having trouble solving problem 2, review \"TensorFlow Linear Function\" section of the class.  If that doesn't help, the solution for this problem is available [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the pixels in the image (28 * 28 = 784)\n",
    "features_count = 784\n",
    "# All the labels\n",
    "labels_count = 10\n",
    "\n",
    "# TODO: Set the features and labels tensors\n",
    "# features = \n",
    "# labels = \n",
    "\n",
    "# TODO: Set the weights and biases tensors\n",
    "# weights = \n",
    "# biases = \n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "\n",
    "#Test Cases\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "\n",
    "assert features._op.name.startswith('Placeholder'), 'features must be a placeholder'\n",
    "assert labels._op.name.startswith('Placeholder'), 'labels must be a placeholder'\n",
    "assert isinstance(weights, Variable), 'weights must be a TensorFlow variable'\n",
    "assert isinstance(biases, Variable), 'biases must be a TensorFlow variable'\n",
    "\n",
    "assert features._shape == None or (\\\n",
    "    features._shape.dims[0].value is None and\\\n",
    "    features._shape.dims[1].value in [None, 784]), 'The shape of features is incorrect'\n",
    "assert labels._shape  == None or (\\\n",
    "    labels._shape.dims[0].value is None and\\\n",
    "    labels._shape.dims[1].value in [None, 10]), 'The shape of labels is incorrect'\n",
    "assert weights._variable._shape == (784, 10), 'The shape of weights is incorrect'\n",
    "assert biases._variable._shape == (10), 'The shape of biases is incorrect'\n",
    "\n",
    "assert features._dtype == tf.float32, 'features must be type float32'\n",
    "assert labels._dtype == tf.float32, 'labels must be type float32'\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "\n",
    "# Linear Function WX + b\n",
    "logits = tf.matmul(features, weights) + biases\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Test Cases\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(loss, feed_dict=train_feed_dict)\n",
    "    session.run(loss, feed_dict=valid_feed_dict)\n",
    "    session.run(loss, feed_dict=test_feed_dict)\n",
    "    biases_data = session.run(biases)\n",
    "\n",
    "assert not np.count_nonzero(biases_data), 'biases must be zeros'\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Learn_Rate_Tune_Image.png\" style=\"height: 70%;width: 70%\">\n",
    "## Problem 3\n",
    "Below are 2 parameter configurations for training the neural network. In each configuration, one of the parameters has multiple options. For each configuration, choose the option that gives the best acccuracy.\n",
    "\n",
    "Parameter configurations:\n",
    "\n",
    "Configuration 1\n",
    "* **Epochs:** 1\n",
    "* **Learning Rate:**\n",
    "  * 0.8\n",
    "  * 0.5\n",
    "  * 0.1\n",
    "  * 0.05\n",
    "  * 0.01\n",
    "\n",
    "Configuration 2\n",
    "* **Epochs:**\n",
    "  * 1\n",
    "  * 2\n",
    "  * 3\n",
    "  * 4\n",
    "  * 5\n",
    "* **Learning Rate:** 0.2\n",
    "\n",
    "The code will print out a Loss and Accuracy graph, so you can see how well the neural network performed.\n",
    "\n",
    "*If you're having trouble solving problem 3, you can view the solution [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 128\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "# epochs = \n",
    "# learning_rate = \n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "You're going to test your model against your hold out dataset/testing data.  This will give you a good indicator of how well the model will do in the real world.  You should have a test accuracy of at least 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "\n",
    "assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
    "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple layers\n",
    "Good job!  You built a one layer TensorFlow network!  However, you might want to build more than one layer.  This is deep learning after all!  In the next section, you will start to satisfy your need for more layers."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
