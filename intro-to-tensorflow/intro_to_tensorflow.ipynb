{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TensorFlow Neural Network Lab</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/notmnist.png\">\n",
    "In this lab, you'll use all the tools you learned from *Introduction to TensorFlow* to label images of English letters! The data you are using, <a href=\"http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html\">notMNIST</a>, consists of images of a letter from A to J in different fonts.\n",
    "\n",
    "The above images are a few examples of the data you'll be training on. After training the network, you will compare your prediction model against test data. Your goal, by the end of this lab, is to make predictions against that test set with at least an 80% accuracy. Let's jump in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this lab, you first need to import all the necessary modules. Run the code below. If it runs successfully, it will print \"`All modules imported`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notMNIST dataset is too large for many computers to handle.  It contains 500,000 images for just training.  You'll be using a subset of this data, 15,000 images for each label (A-J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading notMNIST_train.zip...\n",
      "Download Finished\n",
      "Downloading notMNIST_test.zip...\n",
      "Download Finished\n",
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/210001 [00:00<?, ?files/s]\u001b[A\n",
      "  0%|          | 168/210001 [00:00<02:05, 1677.25files/s]\u001b[A\n",
      "  0%|          | 391/210001 [00:00<01:55, 1809.88files/s]\u001b[A\n",
      "  0%|          | 658/210001 [00:00<01:44, 2002.52files/s]\u001b[A\n",
      "  0%|          | 894/210001 [00:00<01:39, 2097.15files/s]\u001b[A\n",
      "  1%|          | 1114/210001 [00:00<01:38, 2126.36files/s]\u001b[A\n",
      "  1%|          | 1304/210001 [00:00<01:41, 2051.04files/s]\u001b[A\n",
      "  1%|          | 1494/210001 [00:00<02:12, 1569.49files/s]\u001b[A\n",
      "  1%|          | 1660/210001 [00:00<02:12, 1577.15files/s]\u001b[A\n",
      "  1%|          | 1823/210001 [00:01<02:19, 1494.51files/s]\u001b[A\n",
      "  1%|          | 2068/210001 [00:01<02:02, 1691.37files/s]\u001b[A\n",
      "  1%|          | 2287/210001 [00:01<01:54, 1814.44files/s]\u001b[A\n",
      "  1%|          | 2479/210001 [00:01<01:52, 1840.89files/s]\u001b[A\n",
      "  1%|▏         | 2714/210001 [00:01<01:45, 1967.09files/s]\u001b[A\n",
      "  1%|▏         | 2987/210001 [00:01<01:36, 2146.17files/s]\u001b[A\n",
      "  2%|▏         | 3212/210001 [00:01<01:39, 2086.01files/s]\u001b[A\n",
      "  2%|▏         | 3429/210001 [00:01<01:42, 2015.32files/s]\u001b[A\n",
      "  2%|▏         | 3643/210001 [00:01<01:40, 2049.36files/s]\u001b[A\n",
      "  2%|▏         | 3877/210001 [00:01<01:36, 2127.53files/s]\u001b[A\n",
      "  2%|▏         | 4094/210001 [00:02<01:41, 2025.55files/s]\u001b[A\n",
      "  2%|▏         | 4301/210001 [00:02<01:43, 1992.91files/s]\u001b[A\n",
      "  2%|▏         | 4503/210001 [00:02<01:45, 1943.40files/s]\u001b[A\n",
      "  2%|▏         | 4735/210001 [00:02<01:40, 2042.57files/s]\u001b[A\n",
      "  2%|▏         | 4945/210001 [00:02<01:39, 2056.88files/s]\u001b[A\n",
      "  2%|▏         | 5153/210001 [00:02<01:43, 1985.10files/s]\u001b[A\n",
      "  3%|▎         | 5354/210001 [00:02<01:45, 1934.12files/s]\u001b[A\n",
      "  3%|▎         | 5550/210001 [00:02<01:46, 1927.68files/s]\u001b[A\n",
      "  3%|▎         | 5744/210001 [00:02<01:46, 1917.58files/s]\u001b[A\n",
      "  3%|▎         | 5997/210001 [00:03<01:38, 2064.65files/s]\u001b[A\n",
      "  3%|▎         | 6227/210001 [00:03<01:35, 2127.90files/s]\u001b[A\n",
      "  3%|▎         | 6458/210001 [00:03<01:33, 2178.58files/s]\u001b[A\n",
      "  3%|▎         | 6679/210001 [00:03<01:34, 2161.48files/s]\u001b[A\n",
      "  3%|▎         | 6934/210001 [00:03<01:29, 2264.54files/s]\u001b[A\n",
      "  3%|▎         | 7163/210001 [00:03<01:31, 2220.36files/s]\u001b[A\n",
      "  4%|▎         | 7411/210001 [00:03<01:28, 2288.75files/s]\u001b[A\n",
      "  4%|▎         | 7664/210001 [00:03<01:25, 2355.45files/s]\u001b[A\n",
      "  4%|▍         | 7902/210001 [00:03<01:39, 2034.09files/s]\u001b[A\n",
      "  4%|▍         | 8115/210001 [00:04<01:50, 1830.42files/s]\u001b[A\n",
      "  4%|▍         | 8309/210001 [00:04<01:54, 1767.43files/s]\u001b[A\n",
      "  4%|▍         | 8505/210001 [00:04<01:50, 1819.77files/s]\u001b[A\n",
      "  4%|▍         | 8693/210001 [00:04<02:19, 1447.72files/s]\u001b[A\n",
      "  4%|▍         | 8885/210001 [00:04<02:08, 1561.18files/s]\u001b[A\n",
      "  4%|▍         | 9055/210001 [00:04<02:16, 1468.77files/s]\u001b[A\n",
      "  4%|▍         | 9235/210001 [00:04<02:09, 1552.33files/s]\u001b[A\n",
      "  4%|▍         | 9400/210001 [00:04<02:11, 1520.74files/s]\u001b[A\n",
      "  5%|▍         | 9602/210001 [00:04<02:02, 1633.99files/s]\u001b[A\n",
      "  5%|▍         | 9820/210001 [00:05<01:53, 1763.89files/s]\u001b[A\n",
      "  5%|▍         | 10034/210001 [00:05<01:47, 1858.54files/s]\u001b[A\n",
      "  5%|▍         | 10227/210001 [00:05<01:53, 1766.96files/s]\u001b[A\n",
      "  5%|▍         | 10450/210001 [00:05<01:45, 1884.08files/s]\u001b[A\n",
      "  5%|▌         | 10645/210001 [00:05<02:06, 1577.42files/s]\u001b[A\n",
      "  5%|▌         | 10816/210001 [00:05<02:04, 1601.64files/s]\u001b[A\n",
      "  5%|▌         | 10986/210001 [00:05<02:06, 1578.70files/s]\u001b[A\n",
      "  5%|▌         | 11151/210001 [00:05<02:05, 1580.62files/s]\u001b[A\n",
      "  5%|▌         | 11334/210001 [00:05<02:00, 1642.34files/s]\u001b[A\n",
      "  5%|▌         | 11515/210001 [00:06<01:57, 1684.60files/s]\u001b[A\n",
      "  6%|▌         | 11687/210001 [00:06<02:16, 1454.33files/s]\u001b[A\n",
      "  6%|▌         | 11875/210001 [00:06<02:07, 1558.95files/s]\u001b[A\n",
      "  6%|▌         | 12039/210001 [00:06<02:15, 1464.03files/s]\u001b[A\n",
      "  6%|▌         | 12192/210001 [00:06<02:16, 1444.26files/s]\u001b[A\n",
      "  6%|▌         | 12359/210001 [00:06<02:11, 1504.92files/s]\u001b[A\n",
      "  6%|▌         | 12514/210001 [00:06<02:17, 1438.17files/s]\u001b[A\n",
      "  6%|▌         | 12662/210001 [00:06<02:28, 1325.31files/s]\u001b[A\n",
      "  6%|▌         | 12799/210001 [00:07<02:30, 1311.98files/s]\u001b[A\n",
      "  6%|▌         | 12977/210001 [00:07<02:18, 1423.44files/s]\u001b[A\n",
      "  6%|▋         | 13186/210001 [00:07<02:05, 1573.22files/s]\u001b[A\n",
      "  6%|▋         | 13383/210001 [00:07<01:57, 1669.53files/s]\u001b[A\n",
      "  6%|▋         | 13558/210001 [00:07<02:07, 1538.52files/s]\u001b[A\n",
      "  7%|▋         | 13720/210001 [00:07<02:06, 1546.20files/s]\u001b[A\n",
      "  7%|▋         | 13881/210001 [00:07<02:08, 1520.87files/s]\u001b[A\n",
      "  7%|▋         | 14037/210001 [00:07<02:08, 1527.05files/s]\u001b[A\n",
      "  7%|▋         | 14219/210001 [00:07<02:02, 1603.91files/s]\u001b[A\n",
      "  7%|▋         | 14383/210001 [00:08<02:04, 1567.78files/s]\u001b[A\n",
      "  7%|▋         | 14560/210001 [00:08<02:01, 1607.46files/s]\u001b[A\n",
      "  7%|▋         | 14738/210001 [00:08<02:00, 1619.87files/s]\u001b[A\n",
      "  7%|▋         | 14939/210001 [00:08<01:54, 1698.24files/s]\u001b[A\n",
      "  7%|▋         | 15143/210001 [00:08<01:49, 1786.23files/s]\u001b[A\n",
      "  7%|▋         | 15325/210001 [00:08<01:50, 1768.52files/s]\u001b[A\n",
      "  7%|▋         | 15523/210001 [00:08<01:46, 1824.09files/s]\u001b[A\n",
      "  7%|▋         | 15708/210001 [00:08<01:51, 1743.49files/s]\u001b[A\n",
      "  8%|▊         | 15885/210001 [00:08<02:11, 1481.33files/s]\u001b[A\n",
      "  8%|▊         | 16057/210001 [00:09<02:05, 1539.74files/s]\u001b[A\n",
      "  8%|▊         | 16218/210001 [00:09<02:07, 1523.99files/s]\u001b[A\n",
      "  8%|▊         | 16399/210001 [00:09<02:02, 1576.73files/s]\u001b[A\n",
      "  8%|▊         | 16588/210001 [00:09<01:57, 1643.65files/s]\u001b[A\n",
      "  8%|▊         | 16803/210001 [00:09<01:49, 1765.99files/s]\u001b[A\n",
      "  8%|▊         | 16997/210001 [00:09<01:46, 1813.62files/s]\u001b[A\n",
      "  8%|▊         | 17193/210001 [00:09<01:43, 1854.28files/s]\u001b[A\n",
      "  8%|▊         | 17418/210001 [00:09<01:38, 1957.26files/s]\u001b[A\n",
      "  8%|▊         | 17681/210001 [00:09<01:30, 2119.01files/s]\u001b[A\n",
      "  9%|▊         | 17957/210001 [00:09<01:24, 2277.33files/s]\u001b[A\n",
      "  9%|▊         | 18222/210001 [00:10<01:20, 2377.56files/s]\u001b[A\n",
      "  9%|▉         | 18467/210001 [00:10<01:21, 2355.61files/s]\u001b[A\n",
      "  9%|▉         | 18708/210001 [00:10<01:21, 2344.81files/s]\u001b[A\n",
      "  9%|▉         | 18946/210001 [00:10<01:30, 2122.38files/s]\u001b[A\n",
      "  9%|▉         | 19202/210001 [00:10<01:25, 2236.44files/s]\u001b[A\n",
      "  9%|▉         | 19432/210001 [00:10<01:28, 2161.69files/s]\u001b[A\n",
      "  9%|▉         | 19700/210001 [00:10<01:22, 2293.73files/s]\u001b[A\n",
      "  9%|▉         | 19935/210001 [00:10<01:25, 2230.48files/s]\u001b[A\n",
      " 10%|▉         | 20163/210001 [00:10<01:31, 2074.49files/s]\u001b[A\n",
      " 10%|▉         | 20376/210001 [00:11<01:41, 1861.73files/s]\u001b[A\n",
      " 10%|▉         | 20570/210001 [00:11<01:48, 1745.89files/s]\u001b[A\n",
      " 10%|▉         | 20752/210001 [00:11<02:07, 1482.85files/s]\u001b[A\n",
      " 10%|▉         | 20912/210001 [00:11<02:08, 1474.82files/s]\u001b[A\n",
      " 10%|█         | 21069/210001 [00:11<02:05, 1501.42files/s]\u001b[A\n",
      " 10%|█         | 21225/210001 [00:11<02:04, 1515.34files/s]\u001b[A\n",
      " 10%|█         | 21465/210001 [00:11<01:50, 1700.27files/s]\u001b[A\n",
      " 10%|█         | 21833/210001 [00:11<01:32, 2025.00files/s]\u001b[A\n",
      " 11%|█         | 22069/210001 [00:12<01:36, 1952.57files/s]\u001b[A\n",
      " 11%|█         | 22289/210001 [00:12<01:38, 1914.38files/s]\u001b[A\n",
      " 11%|█         | 22609/210001 [00:12<01:26, 2176.33files/s]\u001b[A\n",
      " 11%|█         | 22898/210001 [00:12<01:19, 2348.72files/s]\u001b[A\n",
      " 11%|█         | 23164/210001 [00:12<01:16, 2429.27files/s]\u001b[A\n",
      " 11%|█         | 23441/210001 [00:12<01:14, 2520.59files/s]\u001b[A\n",
      " 11%|█▏        | 23761/210001 [00:12<01:09, 2687.02files/s]\u001b[A\n",
      " 11%|█▏        | 24041/210001 [00:12<01:13, 2532.95files/s]\u001b[A\n",
      " 12%|█▏        | 24304/210001 [00:12<01:16, 2420.47files/s]\u001b[A\n",
      " 12%|█▏        | 24554/210001 [00:12<01:18, 2367.14files/s]\u001b[A\n",
      " 12%|█▏        | 24808/210001 [00:13<01:16, 2413.15files/s]\u001b[A\n",
      " 12%|█▏        | 25054/210001 [00:13<01:20, 2290.88files/s]\u001b[A\n",
      " 12%|█▏        | 25342/210001 [00:13<01:15, 2439.71files/s]\u001b[A\n",
      " 12%|█▏        | 25592/210001 [00:13<01:19, 2309.66files/s]\u001b[A\n",
      " 12%|█▏        | 25829/210001 [00:13<01:22, 2240.72files/s]\u001b[A\n",
      " 12%|█▏        | 26058/210001 [00:13<01:21, 2245.90files/s]\u001b[A\n",
      " 13%|█▎        | 26325/210001 [00:13<01:17, 2357.22files/s]\u001b[A\n",
      " 13%|█▎        | 26658/210001 [00:13<01:10, 2583.16files/s]\u001b[A\n",
      " 13%|█▎        | 26997/210001 [00:13<01:05, 2780.57files/s]\u001b[A\n",
      " 13%|█▎        | 27309/210001 [00:14<01:03, 2873.95files/s]\u001b[A\n",
      " 13%|█▎        | 27605/210001 [00:14<01:12, 2505.54files/s]\u001b[A\n",
      " 13%|█▎        | 27870/210001 [00:14<01:20, 2272.43files/s]\u001b[A\n",
      " 13%|█▎        | 28112/210001 [00:14<01:26, 2099.80files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 28335/210001 [00:14<01:31, 1995.77files/s]\u001b[A\n",
      " 14%|█▎        | 28546/210001 [00:14<01:29, 2026.77files/s]\u001b[A\n",
      " 14%|█▎        | 28771/210001 [00:14<01:27, 2077.47files/s]\u001b[A\n",
      " 14%|█▍        | 29072/210001 [00:14<01:19, 2289.67files/s]\u001b[A\n",
      " 14%|█▍        | 29397/210001 [00:15<01:11, 2510.00files/s]\u001b[A\n",
      " 14%|█▍        | 29750/210001 [00:15<01:05, 2747.72files/s]\u001b[A\n",
      " 14%|█▍        | 30071/210001 [00:15<01:02, 2871.34files/s]\u001b[A\n",
      " 14%|█▍        | 30431/210001 [00:15<00:58, 3055.83files/s]\u001b[A\n",
      " 15%|█▍        | 30772/210001 [00:15<00:56, 3153.63files/s]\u001b[A\n",
      " 15%|█▍        | 31097/210001 [00:15<00:56, 3162.45files/s]\u001b[A\n",
      " 15%|█▍        | 31420/210001 [00:15<01:01, 2908.47files/s]\u001b[A\n",
      " 15%|█▌        | 31774/210001 [00:15<00:58, 3071.84files/s]\u001b[A\n",
      " 15%|█▌        | 32157/210001 [00:15<00:54, 3264.04files/s]\u001b[A\n",
      " 15%|█▌        | 32518/210001 [00:15<00:52, 3359.11files/s]\u001b[A\n",
      " 16%|█▌        | 32865/210001 [00:16<00:52, 3389.86files/s]\u001b[A\n",
      " 16%|█▌        | 33232/210001 [00:16<00:50, 3467.75files/s]\u001b[A\n",
      " 16%|█▌        | 33595/210001 [00:16<00:50, 3513.05files/s]\u001b[A\n",
      " 16%|█▌        | 33952/210001 [00:16<00:49, 3529.65files/s]\u001b[A\n",
      " 16%|█▋        | 34308/210001 [00:16<00:49, 3529.35files/s]\u001b[A\n",
      " 17%|█▋        | 34663/210001 [00:16<00:50, 3483.60files/s]\u001b[A\n",
      " 17%|█▋        | 35013/210001 [00:16<00:50, 3437.26files/s]\u001b[A\n",
      " 17%|█▋        | 35379/210001 [00:16<00:49, 3498.91files/s]\u001b[A\n",
      " 17%|█▋        | 35736/210001 [00:16<00:49, 3518.44files/s]\u001b[A\n",
      " 17%|█▋        | 36089/210001 [00:16<00:49, 3513.98files/s]\u001b[A\n",
      " 17%|█▋        | 36457/210001 [00:17<00:48, 3561.26files/s]\u001b[A\n",
      " 18%|█▊        | 36814/210001 [00:17<00:48, 3543.34files/s]\u001b[A\n",
      " 18%|█▊        | 37173/210001 [00:17<00:48, 3555.93files/s]\u001b[A\n",
      " 18%|█▊        | 37529/210001 [00:17<00:49, 3476.77files/s]\u001b[A\n",
      " 18%|█▊        | 37878/210001 [00:17<00:49, 3471.88files/s]\u001b[A\n",
      " 18%|█▊        | 38226/210001 [00:17<00:49, 3468.12files/s]\u001b[A\n",
      " 18%|█▊        | 38577/210001 [00:17<00:49, 3479.69files/s]\u001b[A\n",
      " 19%|█▊        | 38929/210001 [00:17<00:49, 3489.67files/s]\u001b[A\n",
      " 19%|█▊        | 39279/210001 [00:17<00:49, 3482.53files/s]\u001b[A\n",
      " 19%|█▉        | 39642/210001 [00:17<00:48, 3524.09files/s]\u001b[A\n",
      " 19%|█▉        | 39995/210001 [00:18<00:48, 3502.34files/s]\u001b[A\n",
      " 19%|█▉        | 40362/210001 [00:18<00:47, 3550.46files/s]\u001b[A\n",
      " 19%|█▉        | 40722/210001 [00:18<00:47, 3563.80files/s]\u001b[A\n",
      " 20%|█▉        | 41079/210001 [00:18<00:48, 3517.97files/s]\u001b[A\n",
      " 20%|█▉        | 41432/210001 [00:18<00:48, 3509.93files/s]\u001b[A\n",
      " 20%|█▉        | 41792/210001 [00:18<00:47, 3535.61files/s]\u001b[A\n",
      " 20%|██        | 42164/210001 [00:18<00:46, 3587.36files/s]\u001b[A\n",
      " 20%|██        | 42524/210001 [00:18<00:46, 3569.99files/s]\u001b[A\n",
      " 20%|██        | 42882/210001 [00:18<00:46, 3562.28files/s]\u001b[A\n",
      " 21%|██        | 43239/210001 [00:18<00:47, 3501.30files/s]\u001b[A\n",
      " 21%|██        | 43614/210001 [00:19<00:46, 3570.75files/s]\u001b[A\n",
      " 21%|██        | 43984/210001 [00:19<00:46, 3606.55files/s]\u001b[A\n",
      " 21%|██        | 44346/210001 [00:19<00:46, 3565.34files/s]\u001b[A\n",
      " 21%|██▏       | 44703/210001 [00:19<00:48, 3430.39files/s]\u001b[A\n",
      " 21%|██▏       | 45074/210001 [00:19<00:46, 3509.38files/s]\u001b[A\n",
      " 22%|██▏       | 45440/210001 [00:19<00:46, 3551.63files/s]\u001b[A\n",
      " 22%|██▏       | 45808/210001 [00:19<00:45, 3587.71files/s]\u001b[A\n",
      " 22%|██▏       | 46168/210001 [00:19<00:45, 3584.56files/s]\u001b[A\n",
      " 22%|██▏       | 46557/210001 [00:19<00:44, 3670.20files/s]\u001b[A\n",
      " 22%|██▏       | 46937/210001 [00:20<00:43, 3706.22files/s]\u001b[A\n",
      " 23%|██▎       | 47311/210001 [00:20<00:43, 3713.77files/s]\u001b[A\n",
      " 23%|██▎       | 47683/210001 [00:20<00:43, 3697.17files/s]\u001b[A\n",
      " 23%|██▎       | 48061/210001 [00:20<00:43, 3720.60files/s]\u001b[A\n",
      " 23%|██▎       | 48434/210001 [00:20<00:43, 3682.55files/s]\u001b[A\n",
      " 23%|██▎       | 48818/210001 [00:20<00:43, 3728.20files/s]\u001b[A\n",
      " 23%|██▎       | 49195/210001 [00:20<00:43, 3737.95files/s]\u001b[A\n",
      " 24%|██▎       | 49570/210001 [00:20<00:43, 3726.73files/s]\u001b[A\n",
      " 24%|██▍       | 49943/210001 [00:20<00:43, 3717.65files/s]\u001b[A\n",
      " 24%|██▍       | 50315/210001 [00:20<00:43, 3710.33files/s]\u001b[A\n",
      " 24%|██▍       | 50695/210001 [00:21<00:42, 3735.99files/s]\u001b[A\n",
      " 24%|██▍       | 51072/210001 [00:21<00:42, 3743.81files/s]\u001b[A\n",
      " 24%|██▍       | 51447/210001 [00:21<00:43, 3671.70files/s]\u001b[A\n",
      " 25%|██▍       | 51826/210001 [00:21<00:42, 3701.65files/s]\u001b[A\n",
      " 25%|██▍       | 52197/210001 [00:21<00:42, 3704.04files/s]\u001b[A\n",
      " 25%|██▌       | 52577/210001 [00:21<00:42, 3730.51files/s]\u001b[A\n",
      " 25%|██▌       | 52951/210001 [00:21<00:42, 3705.45files/s]\u001b[A\n",
      " 25%|██▌       | 53322/210001 [00:21<00:42, 3701.94files/s]\u001b[A\n",
      " 26%|██▌       | 53693/210001 [00:21<00:42, 3701.20files/s]\u001b[A\n",
      " 26%|██▌       | 54064/210001 [00:21<00:42, 3642.61files/s]\u001b[A\n",
      " 26%|██▌       | 54429/210001 [00:22<00:44, 3489.11files/s]\u001b[A\n",
      " 26%|██▌       | 54784/210001 [00:22<00:44, 3505.18files/s]\u001b[A\n",
      " 26%|██▋       | 55155/210001 [00:22<00:43, 3562.42files/s]\u001b[A\n",
      " 26%|██▋       | 55513/210001 [00:22<00:53, 2878.22files/s]\u001b[A\n",
      " 27%|██▋       | 55823/210001 [00:22<00:56, 2735.59files/s]\u001b[A\n",
      " 27%|██▋       | 56114/210001 [00:22<01:01, 2506.84files/s]\u001b[A\n",
      " 27%|██▋       | 56381/210001 [00:22<01:09, 2201.29files/s]\u001b[A\n",
      " 27%|██▋       | 56619/210001 [00:22<01:10, 2179.44files/s]\u001b[A\n",
      " 27%|██▋       | 56850/210001 [00:23<01:13, 2069.86files/s]\u001b[A\n",
      " 27%|██▋       | 57089/210001 [00:23<01:11, 2149.31files/s]\u001b[A\n",
      " 27%|██▋       | 57312/210001 [00:23<01:14, 2051.47files/s]\u001b[A\n",
      " 27%|██▋       | 57528/210001 [00:23<01:13, 2081.80files/s]\u001b[A\n",
      " 28%|██▊       | 57761/210001 [00:23<01:10, 2149.30files/s]\u001b[A\n",
      " 28%|██▊       | 57980/210001 [00:23<01:16, 1980.39files/s]\u001b[A\n",
      " 28%|██▊       | 58223/210001 [00:23<01:12, 2095.88files/s]\u001b[A\n",
      " 28%|██▊       | 58448/210001 [00:23<01:10, 2139.41files/s]\u001b[A\n",
      " 28%|██▊       | 58666/210001 [00:23<01:15, 2003.45files/s]\u001b[A\n",
      " 28%|██▊       | 58917/210001 [00:24<01:10, 2131.57files/s]\u001b[A\n",
      " 28%|██▊       | 59174/210001 [00:24<01:07, 2245.94files/s]\u001b[A\n",
      " 28%|██▊       | 59418/210001 [00:24<01:05, 2298.98files/s]\u001b[A\n",
      " 28%|██▊       | 59653/210001 [00:24<01:10, 2134.06files/s]\u001b[A\n",
      " 29%|██▊       | 59936/210001 [00:24<01:05, 2300.55files/s]\u001b[A\n",
      " 29%|██▊       | 60309/210001 [00:24<00:57, 2598.34files/s]\u001b[A\n",
      " 29%|██▉       | 60681/210001 [00:24<00:52, 2855.78files/s]\u001b[A\n",
      " 29%|██▉       | 61064/210001 [00:24<00:48, 3090.58files/s]\u001b[A\n",
      " 29%|██▉       | 61436/210001 [00:24<00:45, 3254.40files/s]\u001b[A\n",
      " 29%|██▉       | 61779/210001 [00:24<00:44, 3303.03files/s]\u001b[A\n",
      " 30%|██▉       | 62121/210001 [00:25<00:45, 3273.64files/s]\u001b[A\n",
      " 30%|██▉       | 62480/210001 [00:25<00:43, 3358.95files/s]\u001b[A\n",
      " 30%|██▉       | 62834/210001 [00:25<00:43, 3409.35files/s]\u001b[A\n",
      " 30%|███       | 63180/210001 [00:25<00:49, 2938.86files/s]\u001b[A\n",
      " 30%|███       | 63555/210001 [00:25<00:46, 3142.39files/s]\u001b[A\n",
      " 30%|███       | 63936/210001 [00:25<00:44, 3315.65files/s]\u001b[A\n",
      " 31%|███       | 64317/210001 [00:25<00:42, 3448.66files/s]\u001b[A\n",
      " 31%|███       | 64681/210001 [00:25<00:41, 3501.85files/s]\u001b[A\n",
      " 31%|███       | 65039/210001 [00:26<00:56, 2584.99files/s]\u001b[A\n",
      " 31%|███       | 65338/210001 [00:26<00:54, 2678.29files/s]\u001b[A\n",
      " 31%|███▏      | 65719/210001 [00:26<00:49, 2937.35files/s]\u001b[A\n",
      " 31%|███▏      | 66102/210001 [00:26<00:45, 3157.34files/s]\u001b[A\n",
      " 32%|███▏      | 66442/210001 [00:26<01:07, 2138.72files/s]\u001b[A\n",
      " 32%|███▏      | 66735/210001 [00:26<01:01, 2326.82files/s]\u001b[A\n",
      " 32%|███▏      | 67033/210001 [00:26<00:57, 2489.04files/s]\u001b[A\n",
      " 32%|███▏      | 67319/210001 [00:26<00:55, 2588.61files/s]\u001b[A\n",
      " 32%|███▏      | 67698/210001 [00:27<00:49, 2859.25files/s]\u001b[A\n",
      " 32%|███▏      | 68074/210001 [00:27<00:46, 3080.65files/s]\u001b[A\n",
      " 33%|███▎      | 68452/210001 [00:27<00:43, 3260.09files/s]\u001b[A\n",
      " 33%|███▎      | 68837/210001 [00:27<00:41, 3416.72files/s]\u001b[A\n",
      " 33%|███▎      | 69229/210001 [00:27<00:39, 3553.41files/s]\u001b[A\n",
      " 33%|███▎      | 69612/210001 [00:27<00:38, 3630.69files/s]\u001b[A\n",
      " 33%|███▎      | 69985/210001 [00:27<00:40, 3419.12files/s]\u001b[A\n",
      " 34%|███▎      | 70365/210001 [00:27<00:39, 3522.67files/s]\u001b[A\n",
      " 34%|███▎      | 70738/210001 [00:27<00:38, 3580.87files/s]\u001b[A\n",
      " 34%|███▍      | 71104/210001 [00:27<00:38, 3602.08files/s]\u001b[A\n",
      " 34%|███▍      | 71468/210001 [00:28<00:39, 3500.26files/s]\u001b[A\n",
      " 34%|███▍      | 71822/210001 [00:28<00:41, 3357.94files/s]\u001b[A\n",
      " 34%|███▍      | 72162/210001 [00:28<01:02, 2199.03files/s]\u001b[A\n",
      " 34%|███▍      | 72437/210001 [00:28<01:09, 1985.67files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 72678/210001 [00:28<01:09, 1969.30files/s]\u001b[A\n",
      " 35%|███▍      | 73033/210001 [00:28<01:00, 2272.40files/s]\u001b[A\n",
      " 35%|███▍      | 73345/210001 [00:28<00:55, 2473.51files/s]\u001b[A\n",
      " 35%|███▌      | 73694/210001 [00:29<00:50, 2709.46files/s]\u001b[A\n",
      " 35%|███▌      | 74044/210001 [00:29<00:46, 2905.11files/s]\u001b[A\n",
      " 35%|███▌      | 74359/210001 [00:29<00:46, 2915.18files/s]\u001b[A\n",
      " 36%|███▌      | 74727/210001 [00:29<00:43, 3104.08files/s]\u001b[A\n",
      " 36%|███▌      | 75112/210001 [00:29<00:40, 3293.74files/s]\u001b[A\n",
      " 36%|███▌      | 75477/210001 [00:29<00:39, 3391.89files/s]\u001b[A\n",
      " 36%|███▌      | 75849/210001 [00:29<00:38, 3483.67files/s]\u001b[A\n",
      " 36%|███▋      | 76227/210001 [00:29<00:37, 3567.36files/s]\u001b[A\n",
      " 36%|███▋      | 76604/210001 [00:29<00:36, 3624.04files/s]\u001b[A\n",
      " 37%|███▋      | 77005/210001 [00:29<00:35, 3729.63files/s]\u001b[A\n",
      " 37%|███▋      | 77382/210001 [00:30<00:36, 3679.98files/s]\u001b[A\n",
      " 37%|███▋      | 77753/210001 [00:30<00:36, 3632.38files/s]\u001b[A\n",
      " 37%|███▋      | 78127/210001 [00:30<00:35, 3663.85files/s]\u001b[A\n",
      " 37%|███▋      | 78506/210001 [00:30<00:35, 3699.92files/s]\u001b[A\n",
      " 38%|███▊      | 78878/210001 [00:30<00:35, 3688.55files/s]\u001b[A\n",
      " 38%|███▊      | 79248/210001 [00:30<00:45, 2876.90files/s]\u001b[A\n",
      " 38%|███▊      | 79616/210001 [00:30<00:42, 3078.33files/s]\u001b[A\n",
      " 38%|███▊      | 79985/210001 [00:30<00:40, 3234.26files/s]\u001b[A\n",
      " 38%|███▊      | 80328/210001 [00:31<00:46, 2793.82files/s]\u001b[A\n",
      " 38%|███▊      | 80632/210001 [00:31<00:50, 2577.96files/s]\u001b[A\n",
      " 39%|███▊      | 80910/210001 [00:31<00:50, 2542.46files/s]\u001b[A\n",
      " 39%|███▊      | 81179/210001 [00:31<00:50, 2549.23files/s]\u001b[A\n",
      " 39%|███▉      | 81462/210001 [00:31<00:48, 2625.23files/s]\u001b[A\n",
      " 39%|███▉      | 81803/210001 [00:31<00:45, 2819.83files/s]\u001b[A\n",
      " 39%|███▉      | 82155/210001 [00:31<00:42, 2997.64files/s]\u001b[A\n",
      " 39%|███▉      | 82465/210001 [00:31<00:49, 2564.95files/s]\u001b[A\n",
      " 39%|███▉      | 82743/210001 [00:31<00:48, 2624.67files/s]\u001b[A\n",
      " 40%|███▉      | 83143/210001 [00:32<00:43, 2925.62files/s]\u001b[A\n",
      " 40%|███▉      | 83519/210001 [00:32<00:40, 3132.95files/s]\u001b[A\n",
      " 40%|███▉      | 83905/210001 [00:32<00:37, 3318.61files/s]\u001b[A\n",
      " 40%|████      | 84253/210001 [00:32<00:38, 3283.08files/s]\u001b[A\n",
      " 40%|████      | 84593/210001 [00:32<00:37, 3304.26files/s]\u001b[A\n",
      " 40%|████      | 84932/210001 [00:32<00:38, 3226.68files/s]\u001b[A\n",
      " 41%|████      | 85289/210001 [00:32<00:37, 3319.61files/s]\u001b[A\n",
      " 41%|████      | 85652/210001 [00:32<00:36, 3406.50files/s]\u001b[A\n",
      " 41%|████      | 86025/210001 [00:32<00:35, 3496.76files/s]\u001b[A\n",
      " 41%|████      | 86389/210001 [00:33<00:34, 3536.38files/s]\u001b[A\n",
      " 41%|████▏     | 86746/210001 [00:33<00:37, 3328.30files/s]\u001b[A\n",
      " 41%|████▏     | 87115/210001 [00:33<00:36, 3412.61files/s]\u001b[A\n",
      " 42%|████▏     | 87475/210001 [00:33<00:35, 3464.19files/s]\u001b[A\n",
      " 42%|████▏     | 87860/210001 [00:33<00:34, 3569.70files/s]\u001b[A\n",
      " 42%|████▏     | 88245/210001 [00:33<00:33, 3647.96files/s]\u001b[A\n",
      " 42%|████▏     | 88613/210001 [00:33<00:34, 3561.14files/s]\u001b[A\n",
      " 42%|████▏     | 88993/210001 [00:33<00:33, 3627.89files/s]\u001b[A\n",
      " 43%|████▎     | 89358/210001 [00:33<00:33, 3605.63files/s]\u001b[A\n",
      " 43%|████▎     | 89720/210001 [00:33<00:34, 3530.95files/s]\u001b[A\n",
      " 43%|████▎     | 90079/210001 [00:34<00:33, 3545.21files/s]\u001b[A\n",
      " 43%|████▎     | 90435/210001 [00:34<00:37, 3225.28files/s]\u001b[A\n",
      " 43%|████▎     | 90799/210001 [00:34<00:35, 3333.35files/s]\u001b[A\n",
      " 43%|████▎     | 91138/210001 [00:34<00:39, 3018.60files/s]\u001b[A\n",
      " 44%|████▎     | 91509/210001 [00:34<00:37, 3196.33files/s]\u001b[A\n",
      " 44%|████▍     | 91897/210001 [00:34<00:35, 3373.13files/s]\u001b[A\n",
      " 44%|████▍     | 92244/210001 [00:34<00:35, 3350.97files/s]\u001b[A\n",
      " 44%|████▍     | 92634/210001 [00:34<00:33, 3498.44files/s]\u001b[A\n",
      " 44%|████▍     | 93006/210001 [00:34<00:32, 3561.86files/s]\u001b[A\n",
      " 44%|████▍     | 93368/210001 [00:35<00:32, 3578.50files/s]\u001b[A\n",
      " 45%|████▍     | 93751/210001 [00:35<00:31, 3647.22files/s]\u001b[A\n",
      " 45%|████▍     | 94119/210001 [00:35<00:31, 3648.33files/s]\u001b[A\n",
      " 45%|████▍     | 94486/210001 [00:35<00:31, 3616.33files/s]\u001b[A\n",
      " 45%|████▌     | 94849/210001 [00:35<00:32, 3594.31files/s]\u001b[A\n",
      " 45%|████▌     | 95239/210001 [00:35<00:31, 3679.16files/s]\u001b[A\n",
      " 46%|████▌     | 95609/210001 [00:35<00:31, 3620.71files/s]\u001b[A\n",
      " 46%|████▌     | 95995/210001 [00:35<00:30, 3687.05files/s]\u001b[A\n",
      " 46%|████▌     | 96365/210001 [00:35<00:30, 3686.43files/s]\u001b[A\n",
      " 46%|████▌     | 96735/210001 [00:35<00:30, 3687.25files/s]\u001b[A\n",
      " 46%|████▌     | 97114/210001 [00:36<00:30, 3715.12files/s]\u001b[A\n",
      " 46%|████▋     | 97502/210001 [00:36<00:29, 3763.06files/s]\u001b[A\n",
      " 47%|████▋     | 97892/210001 [00:36<00:29, 3798.38files/s]\u001b[A\n",
      " 47%|████▋     | 98277/210001 [00:36<00:29, 3813.24files/s]\u001b[A\n",
      " 47%|████▋     | 98669/210001 [00:36<00:28, 3842.42files/s]\u001b[A\n",
      " 47%|████▋     | 99057/210001 [00:36<00:28, 3852.28files/s]\u001b[A\n",
      " 47%|████▋     | 99443/210001 [00:36<00:28, 3839.14files/s]\u001b[A\n",
      " 48%|████▊     | 99828/210001 [00:36<00:29, 3749.28files/s]\u001b[A\n",
      " 48%|████▊     | 100212/210001 [00:36<00:29, 3775.45files/s]\u001b[A\n",
      " 48%|████▊     | 100602/210001 [00:36<00:28, 3809.87files/s]\u001b[A\n",
      " 48%|████▊     | 100989/210001 [00:37<00:28, 3825.65files/s]\u001b[A\n",
      " 48%|████▊     | 101378/210001 [00:37<00:28, 3842.46files/s]\u001b[A\n",
      " 48%|████▊     | 101763/210001 [00:37<00:28, 3843.52files/s]\u001b[A\n",
      " 49%|████▊     | 102148/210001 [00:37<00:28, 3837.96files/s]\u001b[A\n",
      " 49%|████▉     | 102532/210001 [00:37<00:28, 3825.12files/s]\u001b[A\n",
      " 49%|████▉     | 102923/210001 [00:37<00:27, 3850.18files/s]\u001b[A\n",
      " 49%|████▉     | 103310/210001 [00:37<00:27, 3854.42files/s]\u001b[A\n",
      " 49%|████▉     | 103696/210001 [00:37<00:27, 3846.60files/s]\u001b[A\n",
      " 50%|████▉     | 104081/210001 [00:37<00:27, 3829.63files/s]\u001b[A\n",
      " 50%|████▉     | 104471/210001 [00:37<00:27, 3849.08files/s]\u001b[A\n",
      " 50%|████▉     | 104861/210001 [00:38<00:27, 3863.80files/s]\u001b[A\n",
      " 50%|█████     | 105251/210001 [00:38<00:27, 3874.39files/s]\u001b[A\n",
      " 50%|█████     | 105639/210001 [00:38<00:26, 3867.54files/s]\u001b[A\n",
      " 50%|█████     | 106035/210001 [00:38<00:26, 3893.40files/s]\u001b[A\n",
      " 51%|█████     | 106429/210001 [00:38<00:26, 3907.01files/s]\u001b[A\n",
      " 51%|█████     | 106820/210001 [00:38<00:26, 3892.87files/s]\u001b[A\n",
      " 51%|█████     | 107210/210001 [00:38<00:26, 3841.43files/s]\u001b[A\n",
      " 51%|█████     | 107595/210001 [00:38<00:26, 3810.44files/s]\u001b[A\n",
      " 51%|█████▏    | 107991/210001 [00:38<00:26, 3852.34files/s]\u001b[A\n",
      " 52%|█████▏    | 108377/210001 [00:39<00:30, 3373.62files/s]\u001b[A\n",
      " 52%|█████▏    | 108726/210001 [00:39<00:31, 3253.81files/s]\u001b[A\n",
      " 52%|█████▏    | 109129/210001 [00:39<00:29, 3452.55files/s]\u001b[A\n",
      " 52%|█████▏    | 109497/210001 [00:39<00:28, 3515.93files/s]\u001b[A\n",
      " 52%|█████▏    | 109884/210001 [00:39<00:27, 3613.57files/s]\u001b[A\n",
      " 53%|█████▎    | 110275/210001 [00:39<00:26, 3696.40files/s]\u001b[A\n",
      " 53%|█████▎    | 110675/210001 [00:39<00:26, 3781.63files/s]\u001b[A\n",
      " 53%|█████▎    | 111064/210001 [00:39<00:25, 3811.96files/s]\u001b[A\n",
      " 53%|█████▎    | 111474/210001 [00:39<00:25, 3892.01files/s]\u001b[A\n",
      " 53%|█████▎    | 111866/210001 [00:39<00:25, 3860.95files/s]\u001b[A\n",
      " 53%|█████▎    | 112254/210001 [00:40<00:25, 3826.61files/s]\u001b[A\n",
      " 54%|█████▎    | 112638/210001 [00:40<00:27, 3534.24files/s]\u001b[A\n",
      " 54%|█████▍    | 113011/210001 [00:40<00:27, 3590.21files/s]\u001b[A\n",
      " 54%|█████▍    | 113405/210001 [00:40<00:26, 3688.12files/s]\u001b[A\n",
      " 54%|█████▍    | 113798/210001 [00:40<00:25, 3757.18files/s]\u001b[A\n",
      " 54%|█████▍    | 114182/210001 [00:40<00:25, 3780.91files/s]\u001b[A\n",
      " 55%|█████▍    | 114563/210001 [00:40<00:25, 3707.17files/s]\u001b[A\n",
      " 55%|█████▍    | 114936/210001 [00:40<00:27, 3496.34files/s]\u001b[A\n",
      " 55%|█████▍    | 115290/210001 [00:40<00:27, 3388.27files/s]\u001b[A\n",
      " 55%|█████▌    | 115687/210001 [00:41<00:26, 3542.29files/s]\u001b[A\n",
      " 55%|█████▌    | 116054/210001 [00:41<00:26, 3577.76files/s]\u001b[A\n",
      " 55%|█████▌    | 116415/210001 [00:41<00:28, 3322.64files/s]\u001b[A\n",
      " 56%|█████▌    | 116806/210001 [00:41<00:26, 3478.56files/s]\u001b[A\n",
      " 56%|█████▌    | 117202/210001 [00:41<00:25, 3609.38files/s]\u001b[A\n",
      " 56%|█████▌    | 117596/210001 [00:41<00:24, 3700.25files/s]\u001b[A\n",
      " 56%|█████▌    | 117976/210001 [00:41<00:24, 3727.43files/s]\u001b[A\n",
      " 56%|█████▋    | 118367/210001 [00:41<00:24, 3779.19files/s]\u001b[A\n",
      " 57%|█████▋    | 118748/210001 [00:41<00:24, 3730.76files/s]\u001b[A\n",
      " 57%|█████▋    | 119123/210001 [00:41<00:24, 3686.14files/s]\u001b[A\n",
      " 57%|█████▋    | 119493/210001 [00:42<00:24, 3687.11files/s]\u001b[A\n",
      " 57%|█████▋    | 119863/210001 [00:42<00:24, 3677.19files/s]\u001b[A\n",
      " 57%|█████▋    | 120238/210001 [00:42<00:24, 3696.83files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 120616/210001 [00:42<00:24, 3720.43files/s]\u001b[A\n",
      " 58%|█████▊    | 120989/210001 [00:42<00:24, 3702.78files/s]\u001b[A\n",
      " 58%|█████▊    | 121360/210001 [00:42<00:23, 3703.12files/s]\u001b[A\n",
      " 58%|█████▊    | 121731/210001 [00:42<00:23, 3696.23files/s]\u001b[A\n",
      " 58%|█████▊    | 122110/210001 [00:42<00:23, 3721.59files/s]\u001b[A\n",
      " 58%|█████▊    | 122483/210001 [00:42<00:24, 3528.49files/s]\u001b[A\n",
      " 59%|█████▊    | 122860/210001 [00:42<00:24, 3595.91files/s]\u001b[A\n",
      " 59%|█████▊    | 123228/210001 [00:43<00:23, 3620.08files/s]\u001b[A\n",
      " 59%|█████▉    | 123609/210001 [00:43<00:23, 3674.81files/s]\u001b[A\n",
      " 59%|█████▉    | 123991/210001 [00:43<00:23, 3717.00files/s]\u001b[A\n",
      " 59%|█████▉    | 124364/210001 [00:43<00:23, 3618.03files/s]\u001b[A\n",
      " 59%|█████▉    | 124755/210001 [00:43<00:23, 3698.59files/s]\u001b[A\n",
      " 60%|█████▉    | 125148/210001 [00:43<00:22, 3763.24files/s]\u001b[A\n",
      " 60%|█████▉    | 125537/210001 [00:43<00:22, 3797.70files/s]\u001b[A\n",
      " 60%|█████▉    | 125934/210001 [00:43<00:21, 3847.66files/s]\u001b[A\n",
      " 60%|██████    | 126320/210001 [00:43<00:22, 3641.26files/s]\u001b[A\n",
      " 60%|██████    | 126687/210001 [00:43<00:22, 3644.87files/s]\u001b[A\n",
      " 61%|██████    | 127054/210001 [00:44<00:22, 3638.99files/s]\u001b[A\n",
      " 61%|██████    | 127428/210001 [00:44<00:22, 3667.52files/s]\u001b[A\n",
      " 61%|██████    | 127796/210001 [00:44<00:22, 3667.57files/s]\u001b[A\n",
      " 61%|██████    | 128165/210001 [00:44<00:22, 3673.23files/s]\u001b[A\n",
      " 61%|██████    | 128552/210001 [00:44<00:21, 3727.76files/s]\u001b[A\n",
      " 61%|██████▏   | 128926/210001 [00:44<00:21, 3714.02files/s]\u001b[A\n",
      " 62%|██████▏   | 129322/210001 [00:44<00:21, 3779.85files/s]\u001b[A\n",
      " 62%|██████▏   | 129701/210001 [00:44<00:21, 3776.47files/s]\u001b[A\n",
      " 62%|██████▏   | 130080/210001 [00:44<00:21, 3734.22files/s]\u001b[A\n",
      " 62%|██████▏   | 130466/210001 [00:45<00:21, 3770.61files/s]\u001b[A\n",
      " 62%|██████▏   | 130844/210001 [00:45<00:21, 3726.53files/s]\u001b[A\n",
      " 62%|██████▏   | 131218/210001 [00:45<00:21, 3658.90files/s]\u001b[A\n",
      " 63%|██████▎   | 131600/210001 [00:45<00:21, 3703.21files/s]\u001b[A\n",
      " 63%|██████▎   | 131985/210001 [00:45<00:20, 3744.46files/s]\u001b[A\n",
      " 63%|██████▎   | 132370/210001 [00:45<00:20, 3772.82files/s]\u001b[A\n",
      " 63%|██████▎   | 132748/210001 [00:45<00:23, 3335.03files/s]\u001b[A\n",
      " 63%|██████▎   | 133124/210001 [00:45<00:22, 3450.78files/s]\u001b[A\n",
      " 64%|██████▎   | 133516/210001 [00:45<00:21, 3578.36files/s]\u001b[A\n",
      " 64%|██████▍   | 133885/210001 [00:45<00:21, 3610.08files/s]\u001b[A\n",
      " 64%|██████▍   | 134262/210001 [00:46<00:20, 3656.61files/s]\u001b[A\n",
      " 64%|██████▍   | 134640/210001 [00:46<00:20, 3690.43files/s]\u001b[A\n",
      " 64%|██████▍   | 135022/210001 [00:46<00:20, 3727.03files/s]\u001b[A\n",
      " 64%|██████▍   | 135403/210001 [00:46<00:19, 3748.69files/s]\u001b[A\n",
      " 65%|██████▍   | 135799/210001 [00:46<00:19, 3808.37files/s]\u001b[A\n",
      " 65%|██████▍   | 136181/210001 [00:46<00:19, 3760.53files/s]\u001b[A\n",
      " 65%|██████▌   | 136558/210001 [00:46<00:20, 3644.28files/s]\u001b[A\n",
      " 65%|██████▌   | 136924/210001 [00:46<00:20, 3574.80files/s]\u001b[A\n",
      " 65%|██████▌   | 137287/210001 [00:46<00:20, 3589.18files/s]\u001b[A\n",
      " 66%|██████▌   | 137647/210001 [00:47<00:21, 3380.90files/s]\u001b[A\n",
      " 66%|██████▌   | 137989/210001 [00:47<00:21, 3367.74files/s]\u001b[A\n",
      " 66%|██████▌   | 138357/210001 [00:47<00:20, 3454.63files/s]\u001b[A\n",
      " 66%|██████▌   | 138729/210001 [00:47<00:20, 3528.64files/s]\u001b[A\n",
      " 66%|██████▌   | 139084/210001 [00:47<00:23, 3078.41files/s]\u001b[A\n",
      " 66%|██████▋   | 139445/210001 [00:47<00:21, 3220.04files/s]\u001b[A\n",
      " 67%|██████▋   | 139777/210001 [00:47<00:22, 3083.85files/s]\u001b[A\n",
      " 67%|██████▋   | 140094/210001 [00:47<00:23, 3003.44files/s]\u001b[A\n",
      " 67%|██████▋   | 140401/210001 [00:47<00:23, 3014.08files/s]\u001b[A\n",
      " 67%|██████▋   | 140776/210001 [00:47<00:21, 3201.48files/s]\u001b[A\n",
      " 67%|██████▋   | 141141/210001 [00:48<00:20, 3322.17files/s]\u001b[A\n",
      " 67%|██████▋   | 141514/210001 [00:48<00:19, 3432.81files/s]\u001b[A\n",
      " 68%|██████▊   | 141911/210001 [00:48<00:19, 3577.19files/s]\u001b[A\n",
      " 68%|██████▊   | 142299/210001 [00:48<00:18, 3662.13files/s]\u001b[A\n",
      " 68%|██████▊   | 142690/210001 [00:48<00:18, 3731.44files/s]\u001b[A\n",
      " 68%|██████▊   | 143070/210001 [00:48<00:17, 3750.45files/s]\u001b[A\n",
      " 68%|██████▊   | 143448/210001 [00:48<00:17, 3707.27files/s]\u001b[A\n",
      " 68%|██████▊   | 143821/210001 [00:48<00:17, 3700.12files/s]\u001b[A\n",
      " 69%|██████▊   | 144194/210001 [00:48<00:17, 3706.73files/s]\u001b[A\n",
      " 69%|██████▉   | 144566/210001 [00:49<00:17, 3659.65files/s]\u001b[A\n",
      " 69%|██████▉   | 144950/210001 [00:49<00:17, 3711.71files/s]\u001b[A\n",
      " 69%|██████▉   | 145323/210001 [00:49<00:17, 3715.95files/s]\u001b[A\n",
      " 69%|██████▉   | 145696/210001 [00:49<00:17, 3682.74files/s]\u001b[A\n",
      " 70%|██████▉   | 146065/210001 [00:49<00:18, 3545.09files/s]\u001b[A\n",
      " 70%|██████▉   | 146421/210001 [00:49<00:18, 3453.35files/s]\u001b[A\n",
      " 70%|██████▉   | 146793/210001 [00:49<00:17, 3528.90files/s]\u001b[A\n",
      " 70%|███████   | 147186/210001 [00:49<00:17, 3638.77files/s]\u001b[A\n",
      " 70%|███████   | 147572/210001 [00:49<00:16, 3700.07files/s]\u001b[A\n",
      " 70%|███████   | 147967/210001 [00:49<00:16, 3770.20files/s]\u001b[A\n",
      " 71%|███████   | 148360/210001 [00:50<00:16, 3814.50files/s]\u001b[A\n",
      " 71%|███████   | 148755/210001 [00:50<00:15, 3852.63files/s]\u001b[A\n",
      " 71%|███████   | 149142/210001 [00:50<00:15, 3853.97files/s]\u001b[A\n",
      " 71%|███████   | 149531/210001 [00:50<00:15, 3863.27files/s]\u001b[A\n",
      " 71%|███████▏  | 149918/210001 [00:50<00:15, 3851.88files/s]\u001b[A\n",
      " 72%|███████▏  | 150304/210001 [00:50<00:15, 3830.76files/s]\u001b[A\n",
      " 72%|███████▏  | 150688/210001 [00:50<00:15, 3823.98files/s]\u001b[A\n",
      " 72%|███████▏  | 151071/210001 [00:50<00:15, 3812.04files/s]\u001b[A\n",
      " 72%|███████▏  | 151454/210001 [00:50<00:15, 3816.17files/s]\u001b[A\n",
      " 72%|███████▏  | 151836/210001 [00:50<00:15, 3800.09files/s]\u001b[A\n",
      " 72%|███████▏  | 152217/210001 [00:51<00:15, 3714.51files/s]\u001b[A\n",
      " 73%|███████▎  | 152605/210001 [00:51<00:15, 3761.98files/s]\u001b[A\n",
      " 73%|███████▎  | 152990/210001 [00:51<00:15, 3786.06files/s]\u001b[A\n",
      " 73%|███████▎  | 153381/210001 [00:51<00:14, 3820.25files/s]\u001b[A\n",
      " 73%|███████▎  | 153765/210001 [00:51<00:14, 3824.79files/s]\u001b[A\n",
      " 73%|███████▎  | 154150/210001 [00:51<00:14, 3831.34files/s]\u001b[A\n",
      " 74%|███████▎  | 154534/210001 [00:51<00:14, 3778.74files/s]\u001b[A\n",
      " 74%|███████▍  | 154931/210001 [00:51<00:14, 3829.55files/s]\u001b[A\n",
      " 74%|███████▍  | 155322/210001 [00:51<00:14, 3853.33files/s]\u001b[A\n",
      " 74%|███████▍  | 155708/210001 [00:51<00:14, 3799.79files/s]\u001b[A\n",
      " 74%|███████▍  | 156089/210001 [00:52<00:14, 3740.90files/s]\u001b[A\n",
      " 75%|███████▍  | 156472/210001 [00:52<00:14, 3763.04files/s]\u001b[A\n",
      " 75%|███████▍  | 156861/210001 [00:52<00:13, 3799.52files/s]\u001b[A\n",
      " 75%|███████▍  | 157242/210001 [00:52<00:14, 3748.27files/s]\u001b[A\n",
      " 75%|███████▌  | 157629/210001 [00:52<00:13, 3782.57files/s]\u001b[A\n",
      " 75%|███████▌  | 158008/210001 [00:52<00:14, 3486.22files/s]\u001b[A\n",
      " 75%|███████▌  | 158362/210001 [00:52<00:15, 3422.95files/s]\u001b[A\n",
      " 76%|███████▌  | 158751/210001 [00:52<00:14, 3549.13files/s]\u001b[A\n",
      " 76%|███████▌  | 159136/210001 [00:52<00:13, 3633.57files/s]\u001b[A\n",
      " 76%|███████▌  | 159519/210001 [00:53<00:13, 3690.09files/s]\u001b[A\n",
      " 76%|███████▌  | 159912/210001 [00:53<00:13, 3757.00files/s]\u001b[A\n",
      " 76%|███████▋  | 160290/210001 [00:53<00:13, 3714.22files/s]\u001b[A\n",
      " 77%|███████▋  | 160699/210001 [00:53<00:12, 3816.01files/s]\u001b[A\n",
      " 77%|███████▋  | 161083/210001 [00:53<00:12, 3816.93files/s]\u001b[A\n",
      " 77%|███████▋  | 161478/210001 [00:53<00:12, 3852.84files/s]\u001b[A\n",
      " 77%|███████▋  | 161865/210001 [00:53<00:12, 3830.15files/s]\u001b[A\n",
      " 77%|███████▋  | 162257/210001 [00:53<00:12, 3856.18files/s]\u001b[A\n",
      " 77%|███████▋  | 162650/210001 [00:53<00:12, 3876.14files/s]\u001b[A\n",
      " 78%|███████▊  | 163048/210001 [00:53<00:12, 3904.84files/s]\u001b[A\n",
      " 78%|███████▊  | 163439/210001 [00:54<00:11, 3891.39files/s]\u001b[A\n",
      " 78%|███████▊  | 163840/210001 [00:54<00:11, 3925.74files/s]\u001b[A\n",
      " 78%|███████▊  | 164233/210001 [00:54<00:11, 3891.07files/s]\u001b[A\n",
      " 78%|███████▊  | 164623/210001 [00:54<00:11, 3815.36files/s]\u001b[A\n",
      " 79%|███████▊  | 165006/210001 [00:54<00:11, 3792.23files/s]\u001b[A\n",
      " 79%|███████▉  | 165402/210001 [00:54<00:11, 3836.67files/s]\u001b[A\n",
      " 79%|███████▉  | 165791/210001 [00:54<00:11, 3851.75files/s]\u001b[A\n",
      " 79%|███████▉  | 166177/210001 [00:54<00:11, 3848.74files/s]\u001b[A\n",
      " 79%|███████▉  | 166563/210001 [00:54<00:11, 3817.34files/s]\u001b[A\n",
      " 80%|███████▉  | 166953/210001 [00:54<00:11, 3839.78files/s]\u001b[A\n",
      " 80%|███████▉  | 167354/210001 [00:55<00:10, 3888.38files/s]\u001b[A\n",
      " 80%|███████▉  | 167744/210001 [00:55<00:10, 3862.92files/s]\u001b[A\n",
      " 80%|████████  | 168132/210001 [00:55<00:10, 3867.37files/s]\u001b[A\n",
      " 80%|████████  | 168519/210001 [00:55<00:10, 3844.29files/s]\u001b[A\n",
      " 80%|████████  | 168916/210001 [00:55<00:10, 3881.03files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 169321/210001 [00:55<00:10, 3929.72files/s]\u001b[A\n",
      " 81%|████████  | 169715/210001 [00:55<00:10, 3841.64files/s]\u001b[A\n",
      " 81%|████████  | 170120/210001 [00:55<00:10, 3895.41files/s]\u001b[A\n",
      " 81%|████████  | 170511/210001 [00:55<00:10, 3856.33files/s]\u001b[A\n",
      " 81%|████████▏ | 170898/210001 [00:55<00:10, 3831.44files/s]\u001b[A\n",
      " 82%|████████▏ | 171302/210001 [00:56<00:09, 3886.60files/s]\u001b[A\n",
      " 82%|████████▏ | 171700/210001 [00:56<00:09, 3912.17files/s]\u001b[A\n",
      " 82%|████████▏ | 172092/210001 [00:56<00:09, 3869.31files/s]\u001b[A\n",
      " 82%|████████▏ | 172480/210001 [00:56<00:09, 3844.56files/s]\u001b[A\n",
      " 82%|████████▏ | 172865/210001 [00:56<00:09, 3799.97files/s]\u001b[A\n",
      " 82%|████████▏ | 173246/210001 [00:56<00:10, 3628.54files/s]\u001b[A\n",
      " 83%|████████▎ | 173637/210001 [00:56<00:09, 3708.03files/s]\u001b[A\n",
      " 83%|████████▎ | 174033/210001 [00:56<00:09, 3778.29files/s]\u001b[A\n",
      " 83%|████████▎ | 174413/210001 [00:56<00:09, 3771.27files/s]\u001b[A\n",
      " 83%|████████▎ | 174797/210001 [00:56<00:09, 3789.59files/s]\u001b[A\n",
      " 83%|████████▎ | 175187/210001 [00:57<00:09, 3820.80files/s]\u001b[A\n",
      " 84%|████████▎ | 175575/210001 [00:57<00:08, 3838.21files/s]\u001b[A\n",
      " 84%|████████▍ | 175973/210001 [00:57<00:08, 3877.68files/s]\u001b[A\n",
      " 84%|████████▍ | 176362/210001 [00:57<00:08, 3851.19files/s]\u001b[A\n",
      " 84%|████████▍ | 176773/210001 [00:57<00:08, 3924.69files/s]\u001b[A\n",
      " 84%|████████▍ | 177167/210001 [00:57<00:08, 3907.05files/s]\u001b[A\n",
      " 85%|████████▍ | 177569/210001 [00:57<00:08, 3932.13files/s]\u001b[A\n",
      " 85%|████████▍ | 177963/210001 [00:57<00:08, 3919.91files/s]\u001b[A\n",
      " 85%|████████▍ | 178356/210001 [00:57<00:08, 3848.46files/s]\u001b[A\n",
      " 85%|████████▌ | 178755/210001 [00:57<00:08, 3887.28files/s]\u001b[A\n",
      " 85%|████████▌ | 179166/210001 [00:58<00:07, 3950.33files/s]\u001b[A\n",
      " 86%|████████▌ | 179567/210001 [00:58<00:07, 3967.79files/s]\u001b[A\n",
      " 86%|████████▌ | 179967/210001 [00:58<00:07, 3975.59files/s]\u001b[A\n",
      " 86%|████████▌ | 180365/210001 [00:58<00:07, 3970.92files/s]\u001b[A\n",
      " 86%|████████▌ | 180763/210001 [00:58<00:07, 3933.36files/s]\u001b[A\n",
      " 86%|████████▋ | 181157/210001 [00:58<00:07, 3934.72files/s]\u001b[A\n",
      " 86%|████████▋ | 181559/210001 [00:58<00:07, 3959.35files/s]\u001b[A\n",
      " 87%|████████▋ | 181965/210001 [00:58<00:07, 3988.41files/s]\u001b[A\n",
      " 87%|████████▋ | 182364/210001 [00:58<00:07, 3928.03files/s]\u001b[A\n",
      " 87%|████████▋ | 182777/210001 [00:59<00:06, 3984.70files/s]\u001b[A\n",
      " 87%|████████▋ | 183176/210001 [00:59<00:06, 3982.84files/s]\u001b[A\n",
      " 87%|████████▋ | 183575/210001 [00:59<00:06, 3931.97files/s]\u001b[A\n",
      " 88%|████████▊ | 183987/210001 [00:59<00:06, 3983.06files/s]\u001b[A\n",
      " 88%|████████▊ | 184386/210001 [00:59<00:06, 3960.25files/s]\u001b[A\n",
      " 88%|████████▊ | 184793/210001 [00:59<00:06, 3990.38files/s]\u001b[A\n",
      " 88%|████████▊ | 185193/210001 [00:59<00:06, 3989.62files/s]\u001b[A\n",
      " 88%|████████▊ | 185593/210001 [00:59<00:06, 3964.87files/s]\u001b[A\n",
      " 89%|████████▊ | 185995/210001 [00:59<00:06, 3977.28files/s]\u001b[A\n",
      " 89%|████████▉ | 186395/210001 [00:59<00:05, 3983.02files/s]\u001b[A\n",
      " 89%|████████▉ | 186794/210001 [01:00<00:05, 3964.14files/s]\u001b[A\n",
      " 89%|████████▉ | 187191/210001 [01:00<00:06, 3795.58files/s]\u001b[A\n",
      " 89%|████████▉ | 187580/210001 [01:00<00:05, 3819.58files/s]\u001b[A\n",
      " 90%|████████▉ | 187964/210001 [01:00<00:05, 3782.92files/s]\u001b[A\n",
      " 90%|████████▉ | 188344/210001 [01:00<00:05, 3692.20files/s]\u001b[A\n",
      " 90%|████████▉ | 188715/210001 [01:00<00:05, 3652.28files/s]\u001b[A\n",
      " 90%|█████████ | 189082/210001 [01:00<00:06, 3274.20files/s]\u001b[A\n",
      " 90%|█████████ | 189470/210001 [01:00<00:05, 3434.79files/s]\u001b[A\n",
      " 90%|█████████ | 189874/210001 [01:00<00:05, 3593.87files/s]\u001b[A\n",
      " 91%|█████████ | 190260/210001 [01:00<00:05, 3667.61files/s]\u001b[A\n",
      " 91%|█████████ | 190648/210001 [01:01<00:05, 3726.99files/s]\u001b[A\n",
      " 91%|█████████ | 191050/210001 [01:01<00:04, 3809.43files/s]\u001b[A\n",
      " 91%|█████████ | 191435/210001 [01:01<00:04, 3815.90files/s]\u001b[A\n",
      " 91%|█████████▏| 191824/210001 [01:01<00:04, 3836.39files/s]\u001b[A\n",
      " 92%|█████████▏| 192230/210001 [01:01<00:04, 3899.98files/s]\u001b[A\n",
      " 92%|█████████▏| 192622/210001 [01:01<00:04, 3902.91files/s]\u001b[A\n",
      " 92%|█████████▏| 193014/210001 [01:01<00:04, 3876.92files/s]\u001b[A\n",
      " 92%|█████████▏| 193403/210001 [01:01<00:04, 3832.10files/s]\u001b[A\n",
      " 92%|█████████▏| 193788/210001 [01:01<00:04, 3834.92files/s]\u001b[A\n",
      " 92%|█████████▏| 194194/210001 [01:01<00:04, 3895.54files/s]\u001b[A\n",
      " 93%|█████████▎| 194585/210001 [01:02<00:03, 3859.27files/s]\u001b[A\n",
      " 93%|█████████▎| 194974/210001 [01:02<00:03, 3868.25files/s]\u001b[A\n",
      " 93%|█████████▎| 195362/210001 [01:02<00:04, 3471.85files/s]\u001b[A\n",
      " 93%|█████████▎| 195718/210001 [01:02<00:04, 3495.07files/s]\u001b[A\n",
      " 93%|█████████▎| 196107/210001 [01:02<00:03, 3604.82files/s]\u001b[A\n",
      " 94%|█████████▎| 196482/210001 [01:02<00:03, 3646.73files/s]\u001b[A\n",
      " 94%|█████████▎| 196851/210001 [01:02<00:03, 3587.31files/s]\u001b[A\n",
      " 94%|█████████▍| 197246/210001 [01:02<00:03, 3686.18files/s]\u001b[A\n",
      " 94%|█████████▍| 197618/210001 [01:02<00:03, 3624.74files/s]\u001b[A\n",
      " 94%|█████████▍| 198003/210001 [01:03<00:03, 3679.03files/s]\u001b[A\n",
      " 94%|█████████▍| 198409/210001 [01:03<00:03, 3784.71files/s]\u001b[A\n",
      " 95%|█████████▍| 198809/210001 [01:03<00:02, 3844.55files/s]\u001b[A\n",
      " 95%|█████████▍| 199195/210001 [01:03<00:02, 3846.74files/s]\u001b[A\n",
      " 95%|█████████▌| 199585/210001 [01:03<00:02, 3861.73files/s]\u001b[A\n",
      " 95%|█████████▌| 199983/210001 [01:03<00:02, 3895.46files/s]\u001b[A\n",
      " 95%|█████████▌| 200374/210001 [01:03<00:02, 3895.74files/s]\u001b[A\n",
      " 96%|█████████▌| 200765/210001 [01:03<00:02, 3835.33files/s]\u001b[A\n",
      " 96%|█████████▌| 201150/210001 [01:03<00:02, 3821.96files/s]\u001b[A\n",
      " 96%|█████████▌| 201540/210001 [01:03<00:02, 3844.45files/s]\u001b[A\n",
      " 96%|█████████▌| 201927/210001 [01:04<00:02, 3851.75files/s]\u001b[A\n",
      " 96%|█████████▋| 202316/210001 [01:04<00:01, 3861.21files/s]\u001b[A\n",
      " 97%|█████████▋| 202707/210001 [01:04<00:01, 3875.61files/s]\u001b[A\n",
      " 97%|█████████▋| 203095/210001 [01:04<00:01, 3628.78files/s]\u001b[A\n",
      " 97%|█████████▋| 203492/210001 [01:04<00:01, 3723.09files/s]\u001b[A\n",
      " 97%|█████████▋| 203902/210001 [01:04<00:01, 3826.90files/s]\u001b[A\n",
      " 97%|█████████▋| 204288/210001 [01:04<00:01, 3762.62files/s]\u001b[A\n",
      " 97%|█████████▋| 204694/210001 [01:04<00:01, 3845.50files/s]\u001b[A\n",
      " 98%|█████████▊| 205088/210001 [01:04<00:01, 3871.34files/s]\u001b[A\n",
      " 98%|█████████▊| 205477/210001 [01:04<00:01, 3859.80files/s]\u001b[A\n",
      " 98%|█████████▊| 205881/210001 [01:05<00:01, 3910.05files/s]\u001b[A\n",
      " 98%|█████████▊| 206286/210001 [01:05<00:00, 3949.64files/s]\u001b[A\n",
      " 98%|█████████▊| 206682/210001 [01:05<00:00, 3938.90files/s]\u001b[A\n",
      " 99%|█████████▊| 207093/210001 [01:05<00:00, 3985.95files/s]\u001b[A\n",
      " 99%|█████████▉| 207496/210001 [01:05<00:00, 3996.55files/s]\u001b[A\n",
      " 99%|█████████▉| 207896/210001 [01:05<00:00, 3959.85files/s]\u001b[A\n",
      " 99%|█████████▉| 208293/210001 [01:05<00:00, 3897.03files/s]\u001b[A\n",
      " 99%|█████████▉| 208693/210001 [01:05<00:00, 3925.06files/s]\u001b[A\n",
      "100%|█████████▉| 209088/210001 [01:05<00:00, 3932.13files/s]\u001b[A\n",
      "100%|█████████▉| 209482/210001 [01:06<00:00, 3902.65files/s]\u001b[A\n",
      "100%|█████████▉| 209876/210001 [01:06<00:00, 3913.01files/s]\u001b[A\n",
      "100%|██████████| 210001/210001 [01:06<00:00, 3175.08files/s]\u001b[A\n",
      "  0%|          | 0/10001 [00:00<?, ?files/s]\u001b[A\n",
      "  4%|▍         | 378/10001 [00:00<00:02, 3777.70files/s]\u001b[A\n",
      "  8%|▊         | 787/10001 [00:00<00:02, 3864.02files/s]\u001b[A\n",
      " 12%|█▏        | 1186/10001 [00:00<00:02, 3900.00files/s]\u001b[A\n",
      " 16%|█▌        | 1600/10001 [00:00<00:02, 3968.88files/s]\u001b[A\n",
      " 20%|█▉        | 1991/10001 [00:00<00:02, 3948.13files/s]\u001b[A\n",
      " 24%|██▍       | 2387/10001 [00:00<00:01, 3950.80files/s]\u001b[A\n",
      " 28%|██▊       | 2767/10001 [00:00<00:01, 3904.28files/s]\u001b[A\n",
      " 31%|███▏      | 3143/10001 [00:00<00:01, 3858.78files/s]\u001b[A\n",
      " 35%|███▌      | 3533/10001 [00:00<00:01, 3869.74files/s]\u001b[A\n",
      " 39%|███▉      | 3909/10001 [00:01<00:01, 3834.75files/s]\u001b[A\n",
      " 43%|████▎     | 4285/10001 [00:01<00:01, 3809.83files/s]\u001b[A\n",
      " 47%|████▋     | 4659/10001 [00:01<00:01, 3709.09files/s]\u001b[A\n",
      " 50%|█████     | 5032/10001 [00:01<00:01, 3713.61files/s]\u001b[A\n",
      " 54%|█████▍    | 5401/10001 [00:01<00:01, 3631.28files/s]\u001b[A\n",
      " 58%|█████▊    | 5763/10001 [00:01<00:01, 3086.94files/s]\u001b[A\n",
      " 61%|██████▏   | 6137/10001 [00:01<00:01, 3257.41files/s]\u001b[A\n",
      " 65%|██████▍   | 6475/10001 [00:01<00:01, 3202.29files/s]\u001b[A\n",
      " 68%|██████▊   | 6832/10001 [00:01<00:00, 3301.98files/s]\u001b[A\n",
      " 72%|███████▏  | 7169/10001 [00:01<00:00, 3215.08files/s]\u001b[A\n",
      " 75%|███████▌  | 7537/10001 [00:02<00:00, 3340.77files/s]\u001b[A\n",
      " 79%|███████▉  | 7922/10001 [00:02<00:00, 3475.71files/s]\u001b[A\n",
      " 83%|████████▎ | 8303/10001 [00:02<00:00, 3567.69files/s]\u001b[A\n",
      " 87%|████████▋ | 8699/10001 [00:02<00:00, 3674.53files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9095/10001 [00:02<00:00, 3753.91files/s]\u001b[A\n",
      " 95%|█████████▍| 9474/10001 [00:02<00:00, 3741.66files/s]\u001b[A\n",
      " 99%|█████████▉| 9876/10001 [00:02<00:00, 3817.63files/s]\u001b[A\n",
      "100%|██████████| 10001/10001 [00:02<00:00, 3656.80files/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Mean_Variance_Image.png\" style=\"height: 75%;width: 75%; position: relative; right: 5%\">\n",
    "## Problem 1\n",
    "The first problem involves normalizing the features for your training and test data.\n",
    "\n",
    "Implement Min-Max scaling in the `normalize_grayscale()` function to a range of `a=0.1` and `b=0.9`. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.\n",
    "\n",
    "Since the raw notMNIST image data is in [grayscale](https://en.wikipedia.org/wiki/Grayscale), the current values range from a min of 0 to a max of 255.\n",
    "\n",
    "Min-Max Scaling:\n",
    "$\n",
    "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
    "$\n",
    "\n",
    "*If you're having trouble solving problem 1, you can view the solution [here](https://github.com/udacity/deep-learning/blob/master/intro-to-tensorflow/intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    return 0.1 + (image_data * 0.8) / 255\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to pickle file...\n",
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "All your progress is now saved to the pickle file.  If you need to leave and comeback to this lab, you no longer have to start from the beginning.  Just run the code block below and it will load all the data and modules required to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2\n",
    "\n",
    "Now it's time to build a simple neural network using TensorFlow. Here, your network will be just an input layer and an output layer.\n",
    "\n",
    "<img src=\"image/network_diagram.png\" style=\"height: 40%;width: 40%; position: relative; right: 10%\">\n",
    "\n",
    "For the input here the images have been flattened into a vector of $28 \\times 28 = 784$ features. Then, we're trying to predict the image digit so there are 10 output units, one for each label. Of course, feel free to add hidden layers if you want, but this notebook is built to guide you through a single layer network. \n",
    "\n",
    "For the neural network to train on your data, you need the following <a href=\"https://www.tensorflow.org/resources/dims_types.html#data-types\">float32</a> tensors:\n",
    " - `features`\n",
    "  - Placeholder tensor for feature data (`train_features`/`valid_features`/`test_features`)\n",
    " - `labels`\n",
    "  - Placeholder tensor for label data (`train_labels`/`valid_labels`/`test_labels`)\n",
    " - `weights`\n",
    "  - Variable Tensor with random numbers from a truncated normal distribution.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#truncated_normal\">`tf.truncated_normal()` documentation</a> for help.\n",
    " - `biases`\n",
    "  - Variable Tensor with all zeros.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#zeros\"> `tf.zeros()` documentation</a> for help.\n",
    "\n",
    "*If you're having trouble solving problem 2, review \"TensorFlow Linear Function\" section of the class.  If that doesn't help, the solution for this problem is available [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# All the pixels in the image (28 * 28 = 784)\n",
    "features_count = 784\n",
    "# All the labels\n",
    "labels_count = 10\n",
    "\n",
    "\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "weights = tf.Variable(tf.truncated_normal((features_count, labels_count)))\n",
    "biases = tf.Variable(tf.zeros(labels_count))\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "\n",
    "#Test Cases\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "\n",
    "assert features._op.name.startswith('Placeholder'), 'features must be a placeholder'\n",
    "assert labels._op.name.startswith('Placeholder'), 'labels must be a placeholder'\n",
    "assert isinstance(weights, Variable), 'weights must be a TensorFlow variable'\n",
    "assert isinstance(biases, Variable), 'biases must be a TensorFlow variable'\n",
    "\n",
    "assert features._shape == None or (\\\n",
    "    features._shape.dims[0].value is None and\\\n",
    "    features._shape.dims[1].value in [None, 784]), 'The shape of features is incorrect'\n",
    "assert labels._shape  == None or (\\\n",
    "    labels._shape.dims[0].value is None and\\\n",
    "    labels._shape.dims[1].value in [None, 10]), 'The shape of labels is incorrect'\n",
    "assert weights._variable._shape == (784, 10), 'The shape of weights is incorrect'\n",
    "assert biases._variable._shape == (10), 'The shape of biases is incorrect'\n",
    "\n",
    "assert features._dtype == tf.float32, 'features must be type float32'\n",
    "assert labels._dtype == tf.float32, 'labels must be type float32'\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "\n",
    "# Linear Function WX + b\n",
    "logits = tf.matmul(features, weights) + biases\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Test Cases\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(loss, feed_dict=train_feed_dict)\n",
    "    session.run(loss, feed_dict=valid_feed_dict)\n",
    "    session.run(loss, feed_dict=test_feed_dict)\n",
    "    biases_data = session.run(biases)\n",
    "\n",
    "assert not np.count_nonzero(biases_data), 'biases must be zeros'\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Learn_Rate_Tune_Image.png\" style=\"height: 70%;width: 70%\">\n",
    "## Problem 3\n",
    "Below are 2 parameter configurations for training the neural network. In each configuration, one of the parameters has multiple options. For each configuration, choose the option that gives the best acccuracy.\n",
    "\n",
    "Parameter configurations:\n",
    "\n",
    "Configuration 1\n",
    "* **Epochs:** 1\n",
    "* **Learning Rate:**\n",
    "  * 0.8\n",
    "  * 0.5\n",
    "  * 0.1\n",
    "  * 0.05\n",
    "  * 0.01\n",
    "\n",
    "Configuration 2\n",
    "* **Epochs:**\n",
    "  * 1\n",
    "  * 2\n",
    "  * 3\n",
    "  * 4\n",
    "  * 5\n",
    "* **Learning Rate:** 0.2\n",
    "\n",
    "The code will print out a Loss and Accuracy graph, so you can see how well the neural network performed.\n",
    "\n",
    "*If you're having trouble solving problem 3, you can view the solution [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/3: 100%|██████████| 1114/1114 [00:10<00:00, 106.05batches/s]\n",
      "Epoch  2/3: 100%|██████████| 1114/1114 [00:08<00:00, 128.83batches/s]\n",
      "Epoch  3/3: 100%|██████████| 1114/1114 [00:08<00:00, 127.66batches/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcaVrIEyxhjjStZAGWOMcaX/A+hof0X8p+KJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120e76e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.7549333572387695\n"
     ]
    }
   ],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 128\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 3\n",
    "learning_rate = 0.03\n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "You're going to test your model against your hold out dataset/testing data.  This will give you a good indicator of how well the model will do in the real world.  You should have a test accuracy of at least 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/3: 100%|██████████| 1114/1114 [00:01<00:00, 770.50batches/s]\n",
      "Epoch  2/3: 100%|██████████| 1114/1114 [00:01<00:00, 743.25batches/s]\n",
      "Epoch  3/3: 100%|██████████| 1114/1114 [00:01<00:00, 780.99batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice Job! Test Accuracy is 0.8112999796867371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "\n",
    "assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
    "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple layers\n",
    "Good job!  You built a one layer TensorFlow network!  However, you might want to build more than one layer.  This is deep learning after all!  In the next section, you will start to satisfy your need for more layers."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
